{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AUEB M.Sc. in Data Science (part-time)\n",
        "\n",
        "### 2024.04 - 2024.06\n",
        "\n",
        "## PROJECT 03: Develop a sentiment classifier for a kind of texts of your choice\n",
        "\n",
        "\n",
        "**Course**: Text Analytics   \n",
        "**Authors**:\n",
        "Anagnos Theodoros (p3352323) -\n",
        "Michalopoulos Ioannis (p3352314) -\n",
        "Kafantaris Panagiotis (p3352328) -  \n",
        "Vigkos Ioannis (p3352326)\n",
        "\n",
        "**Date**: 2024-04-29"
      ],
      "metadata": {
        "id": "tK3BwlKbHtta"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIsQ1YDRGI4w"
      },
      "source": [
        "# Assignment 09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVs-34KdGI4x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "\n",
        "df = pd.read_excel('LabeledText.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kDRRb3iGI4y"
      },
      "outputs": [],
      "source": [
        "# Set display options to show all columns and rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WH6I3fqGI4y"
      },
      "outputs": [],
      "source": [
        "#keep only the columns we need\n",
        "df=df[['Caption','LABEL']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "pukTlzITGI4y",
        "outputId": "bd78ea5e-8f66-4ee5-bc8b-22d0dbcfa938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories\n",
            "['negative' 'positive' 'neutral']\n",
            "-------------\n",
            "Dataset Sample\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                 Caption  \\\n",
              "0                                                                          How I feel today #legday #jelly #aching #gym    \n",
              "1                    @ArrivaTW absolute disgrace two carriages from Bangor half way there standing room only #disgraced    \n",
              "2  This is my Valentine's from 1 of my nephews. I am elated; sometimes the little things are the biggest & best things!    \n",
              "3                          betterfeelingfilms: RT via Instagram: First day of filming #powerless back in 2011. Can't ¡­    \n",
              "4                                                                             Zoe's first love #Rattled @JohnnyHarper15    \n",
              "\n",
              "      LABEL  \n",
              "0  negative  \n",
              "1  negative  \n",
              "2  positive  \n",
              "3   neutral  \n",
              "4  positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a759e616-2097-42f3-b4ba-2c318166dd3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Caption</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How I feel today #legday #jelly #aching #gym</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@ArrivaTW absolute disgrace two carriages from Bangor half way there standing room only #disgraced</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is my Valentine's from 1 of my nephews. I am elated; sometimes the little things are the biggest &amp; best things!</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>betterfeelingfilms: RT via Instagram: First day of filming #powerless back in 2011. Can't ¡­</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zoe's first love #Rattled @JohnnyHarper15</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a759e616-2097-42f3-b4ba-2c318166dd3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a759e616-2097-42f3-b4ba-2c318166dd3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a759e616-2097-42f3-b4ba-2c318166dd3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93369e9c-9aaa-4e9a-b917-fe2840fb1c87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93369e9c-9aaa-4e9a-b917-fe2840fb1c87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93369e9c-9aaa-4e9a-b917-fe2840fb1c87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4869,\n  \"fields\": [\n    {\n      \"column\": \"Caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4663,\n        \"samples\": [\n          \"This just turned my whole entire day around ??? ... One day she gone be mines \",\n          \"When your mirror foggy (me my self and lil sis ???????? \",\n          \"Absolutely incensed by this cynical 50 Shades/Valentine cash-in at Tesco \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"positive\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Print unique categories/labels in the dataset\n",
        "print('Categories')\n",
        "print(df.LABEL.unique())\n",
        "print(\"-------------\")\n",
        "\n",
        "# Print a sample of the dataset\n",
        "print('Dataset Sample')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFZZBmZlGI4z"
      },
      "source": [
        "## Data Cleansing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRfCfGmlGI4z"
      },
      "source": [
        "This section focuses on preparing the text data for analysis by performing various preprocessing steps. It includes tasks such as removing URLs, HTML tags, punctuation, numbers, and stop words, as well as expanding contractions and lemmatizing words. Additionally, it ensures consistency and standardization in the text data, which is essential for accurate and reliable natural language processing tasks, such as sentiment analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGZVR1vQGI4z"
      },
      "outputs": [],
      "source": [
        "# Lowercase the data\n",
        "df['text_cleaned'] = df['Caption'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb-fQZzpGI40",
        "outputId": "af072d1a-0734-408e-d606-6d111b40f9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8b9b66f9a82c>:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  df['text_cleaned'] = df['text_cleaned'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)\n"
          ]
        }
      ],
      "source": [
        "!pip install lxml\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Removing URLs from the text\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'http\\S+|www.\\S+', '', x))\n",
        "\n",
        "# Removing HTML tags from the text\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: BeautifulSoup(x, \"html.parser\").text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y0LtcBaGI40"
      },
      "outputs": [],
      "source": [
        "# Dictionary to convert common chat words to their full forms\n",
        "#There are many more chat words that can be added to this dictionary. These are some common examples.\n",
        "chat_words_dict = {\n",
        "    \"imo\": \"in my opinion\",\n",
        "     \"cyaa\": \"see you\",\n",
        "    \"idk\": \"I don't know\",\n",
        "    \"rn\": \"right now\",\n",
        "    \"afaik\": \"as far as I know\",\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfntdNPWGI40"
      },
      "outputs": [],
      "source": [
        "# Function that returns the text with chat words converted to their full forms\n",
        "\n",
        "def convert_chat_words(text):\n",
        "    words = text.split()\n",
        "    converted_words = []\n",
        "    for word in words:\n",
        "        if word.lower() in chat_words_dict:\n",
        "            converted_words.append(chat_words_dict[word.lower()])\n",
        "        else:\n",
        "            converted_words.append(word)\n",
        "    converted_text = \" \".join(converted_words)\n",
        "    return converted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsb68t6oGI40"
      },
      "outputs": [],
      "source": [
        "df['text_cleaned'] = df['text_cleaned'].apply(convert_chat_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xzVvILtGI40"
      },
      "outputs": [],
      "source": [
        "# Removing punctuation\n",
        "import string\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Removing numbers\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "# Removing extra spaces\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join(x.split()))\n",
        "\n",
        "# Replacing repetitions of punctuation\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'(\\W)\\1+', r'\\1', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbvh77TvGI41"
      },
      "outputs": [],
      "source": [
        "# Removing special characters\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r\"[^\\w\\s]\", '', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwgsAhAXGI41",
        "outputId": "5a185030-8076-45eb-95ff-cb9dceea6541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "\n",
        "# Removing contractions\n",
        "import contractions\n",
        "# Remove contractions from the 'text_cleaned' column\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: contractions.fix(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69MtwSaRGI41",
        "outputId": "dc14b669-1737-4ac0-dfe3-ec84277f4f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Tokenization\n",
        "df['tokens'] = df['text_cleaned'].apply(lambda x: word_tokenize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGKfLX-UGI41",
        "outputId": "894a6c88-6b45-4e16-8368-0b9dcf74575b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4849              [get, friday, night, look, sorted, newin, lbd, littleblackdress, strappy, plunge, neckline, mini, black, bodycon]\n",
              "4850                                                                                         [rt, nneagoe, love, caring, beautiful]\n",
              "4851               [february, winter, rainy, stormy, windy, wednesday, morning, love, happy, positive, passionate, reading, coffee]\n",
              "4852    [rt, thatguykai, honored, pittsburgh, pirates, consultant, coachotip, speak, ball, club, passionate, relentless, ownership]\n",
              "4853                                              [genghis, khan, ily, relatable, king, passionate, yeet, yas, sogengrn, apgenghis]\n",
              "4854                 [february, winter, rainy, stormy, windy, wednesday, evening, love, happy, positive, passionate, calm, fun, uk]\n",
              "4855                  [february, winter, rainy, stormy, windy, wednesday, evening, love, happy, positive, passionate, calm, coffee]\n",
              "4856                                                   [rt, bishopcarrollhs, great, bishopcarrollhs, students, caring, empowerbchs]\n",
              "4857                                         [big, thank, teachers, attended, isabcpdªso, nice, meet, passionate, educators, isabc]\n",
              "4858                                                                                                          [dave, looks, elated]\n",
              "4859                                                [dbel, scared, veryscared, holding, owt, hot, coming, nearer, david, petrified]\n",
              "4860                                           [completely, unique, petrified, palm, earrings, set, sterling, silver, fossil, gift]\n",
              "4861                                                               [rt, headquarters, fair, everything, makes, want, scream, anger]\n",
              "4862                                [fanghorn, forest, alder, woodland, glen, vorlich, lochearn, petrified, forest, lotr, scotland]\n",
              "4863                                                                                       [whisk, way, powerless, bakersgonnabake]\n",
              "4864                                                                   [omg, well, done, eskom, man, dies, loadshedding, powerless]\n",
              "4865                                                                                          [feelin, love, valentinesday, caring]\n",
              "4866                                                                                                           [blue, eyes, beaten]\n",
              "4867                                                                                      [la, chucha, louuu, te, chupo, los, ojos]\n",
              "4868                                      [colorsplashbw, zealous, remedios, herbales, tratamientos, naturales, remedios, herbales]\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Removing stop words\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Loading English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Removing stop words from the 'tokens' column\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# Print the updated 'tokens' column\n",
        "df['tokens'].tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJS5S5sNGI41",
        "outputId": "a5011791-49d8-4736-ab1c-8a369df3c8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Create an instance of WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# POS tag mapping dictionary\n",
        "wordnet_map = {\"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"J\": wordnet.ADJ, \"R\": wordnet.ADV}\n",
        "\n",
        "# Function to perform Lemmatization on a text\n",
        "def lemmatize_text(text):\n",
        "    # Get the POS tags for the words\n",
        "    pos_tags = nltk.pos_tag(text)\n",
        "\n",
        "    # Perform Lemmatization\n",
        "    lemmatized_words = []\n",
        "    for word, tag in pos_tags:\n",
        "        # Map the POS tag to WordNet POS tag\n",
        "        pos = wordnet_map.get(tag[0].upper(), wordnet.NOUN)\n",
        "        # Lemmatize the word with the appropriate POS tag\n",
        "        lemmatized_word = lemmatizer.lemmatize(word, pos=pos)\n",
        "        # Add the lemmatized word to the list\n",
        "        lemmatized_words.append(lemmatized_word)\n",
        "\n",
        "    return lemmatized_words\n",
        "\n",
        "# Apply Lemmatization to the 'tokens' column\n",
        "df['tokens'] = df['tokens'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "wupZSOoDGI41",
        "outputId": "01eb1409-d1af-402e-e80b-a4b68673e0d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                 Caption  \\\n",
              "0                                                                          How I feel today #legday #jelly #aching #gym    \n",
              "1                    @ArrivaTW absolute disgrace two carriages from Bangor half way there standing room only #disgraced    \n",
              "2  This is my Valentine's from 1 of my nephews. I am elated; sometimes the little things are the biggest & best things!    \n",
              "3                          betterfeelingfilms: RT via Instagram: First day of filming #powerless back in 2011. Can't ¡­    \n",
              "4                                                                             Zoe's first love #Rattled @JohnnyHarper15    \n",
              "\n",
              "      LABEL  \\\n",
              "0  negative   \n",
              "1  negative   \n",
              "2  positive   \n",
              "3   neutral   \n",
              "4  positive   \n",
              "\n",
              "                                                                                                   text_cleaned  \\\n",
              "0                                                                      how i feel today legday jelly aching gym   \n",
              "1              arrivatw absolute disgrace two carriages from bangor half way there standing room only disgraced   \n",
              "2  this is my valentines from of my nephews i am elated sometimes the little things are the biggest best things   \n",
              "3                            betterfeelingfilms rt via instagram first day of filming powerless back in cannot    \n",
              "4                                                                          zoes first love rattled johnnyharper   \n",
              "\n",
              "                                                                                    tokens  \n",
              "0                                                  [feel, today, legday, jelly, ache, gym]  \n",
              "1  [arrivatw, absolute, disgrace, two, carriage, bangor, half, way, stand, room, disgrace]  \n",
              "2                   [valentine, nephew, elate, sometimes, little, thing, big, best, thing]  \n",
              "3              [betterfeelingfilms, rt, via, instagram, first, day, film, powerless, back]  \n",
              "4                                                [zoes, first, love, rattle, johnnyharper]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45db4b37-26b3-4bf5-85f2-81effcf7c9d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Caption</th>\n",
              "      <th>LABEL</th>\n",
              "      <th>text_cleaned</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How I feel today #legday #jelly #aching #gym</td>\n",
              "      <td>negative</td>\n",
              "      <td>how i feel today legday jelly aching gym</td>\n",
              "      <td>[feel, today, legday, jelly, ache, gym]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@ArrivaTW absolute disgrace two carriages from Bangor half way there standing room only #disgraced</td>\n",
              "      <td>negative</td>\n",
              "      <td>arrivatw absolute disgrace two carriages from bangor half way there standing room only disgraced</td>\n",
              "      <td>[arrivatw, absolute, disgrace, two, carriage, bangor, half, way, stand, room, disgrace]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is my Valentine's from 1 of my nephews. I am elated; sometimes the little things are the biggest &amp; best things!</td>\n",
              "      <td>positive</td>\n",
              "      <td>this is my valentines from of my nephews i am elated sometimes the little things are the biggest best things</td>\n",
              "      <td>[valentine, nephew, elate, sometimes, little, thing, big, best, thing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>betterfeelingfilms: RT via Instagram: First day of filming #powerless back in 2011. Can't ¡­</td>\n",
              "      <td>neutral</td>\n",
              "      <td>betterfeelingfilms rt via instagram first day of filming powerless back in cannot</td>\n",
              "      <td>[betterfeelingfilms, rt, via, instagram, first, day, film, powerless, back]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zoe's first love #Rattled @JohnnyHarper15</td>\n",
              "      <td>positive</td>\n",
              "      <td>zoes first love rattled johnnyharper</td>\n",
              "      <td>[zoes, first, love, rattle, johnnyharper]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45db4b37-26b3-4bf5-85f2-81effcf7c9d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45db4b37-26b3-4bf5-85f2-81effcf7c9d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45db4b37-26b3-4bf5-85f2-81effcf7c9d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c731503-31b8-48f6-8cbb-b9b49033523f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c731503-31b8-48f6-8cbb-b9b49033523f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c731503-31b8-48f6-8cbb-b9b49033523f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4869,\n  \"fields\": [\n    {\n      \"column\": \"Caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4663,\n        \"samples\": [\n          \"This just turned my whole entire day around ??? ... One day she gone be mines \",\n          \"When your mirror foggy (me my self and lil sis ???????? \",\n          \"Absolutely incensed by this cynical 50 Shades/Valentine cash-in at Tesco \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"positive\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4532,\n        \"samples\": [\n          \"rt bruk russian footballs miss charming stripped of title after being exposed as a racist neonazi\",\n          \"do you like vampiresforget twilightthe addiction abelferrara movie about good evil and catharsis\",\n          \"bit of bleakness bleak blackandwhite columns trees\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFsdWZAQGI42"
      },
      "source": [
        "## Train-Test split of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sn_n6DZGI42"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and validation sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.tokens,\n",
        "                                                  df.LABEL,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=12547392)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21b2-5HwGI42",
        "outputId": "4f323024-c76f-4b71-fb19-f6fb5d7f080e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1807             [rt, dallasblackcom, horrible, news, los, angeles, today, regard, khloes, estrange, husband, lamar, odom]\n",
            "1619                                                                                          [feel, desolate, take, quiz]\n",
            "526     [rt, bosshogswife, duckcommanderkidsdevo, release, today, book, much, fun, read, kiddos, chryssymama, excite, htt]\n",
            "915                                                                          [indias, modi, appal, temple, build, worship]\n",
            "3485                                                      [photo, photographer, get, rumble, jungle, beat, stone, gorilla]\n",
            "Name: tokens, dtype: object\n",
            "1807    negative\n",
            "1619    negative\n",
            "526     positive\n",
            "915     negative\n",
            "3485     neutral\n",
            "Name: LABEL, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X_train.head())\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5phC1LQGI42",
        "outputId": "172e1089-c27b-4a60-d02a-5d81f89b9dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3408\n",
            "3408\n",
            "1461\n",
            "1461\n"
          ]
        }
      ],
      "source": [
        "# Printing the lengths of the training and validation sets\n",
        "\n",
        "print(len(X_train)) # Number of samples in the training set\n",
        "print(len(y_train))  # Number of labels in the training set\n",
        "print(len(X_val))  # Number of samples in the validation set\n",
        "print(len(y_val))  # Number of labels in the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlE0XcgsGI42"
      },
      "source": [
        "## Create TF-IDF features and apply SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgshG6t_GI42"
      },
      "source": [
        "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "TF-IDF measures word importance in a document compared to its frequency in a collection of documents. Higher scores indicate more relevance.\n",
        "\n",
        "SVD (Singular Value Decomposition)\n",
        "SVD reduces data dimensions while preserving important information. It's often used with TF-IDF matrices in text analysis to improve efficiency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6TSjnb8GI42"
      },
      "outputs": [],
      "source": [
        "# Resetting the index of X_train and X_val\n",
        "# To ensure that they start from 0 and are consecutive after any previous operations that might have altered the index\n",
        "\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_val.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCpS3ebjGI42"
      },
      "outputs": [],
      "source": [
        "# Resetting the index of y_train and y_val\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "y_val.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vloOu8_qGI43",
        "outputId": "e67bd3dc-5066-4525-d498-9919e45f47eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             [rt, dallasblackcom, horrible, news, los, angeles, today, regard, khloes, estrange, husband, lamar, odom]\n",
              "1                                                                                          [feel, desolate, take, quiz]\n",
              "2    [rt, bosshogswife, duckcommanderkidsdevo, release, today, book, much, fun, read, kiddos, chryssymama, excite, htt]\n",
              "3                                                                         [indias, modi, appal, temple, build, worship]\n",
              "4                                                      [photo, photographer, get, rumble, jungle, beat, stone, gorilla]\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNy0NkswGI43",
        "outputId": "1f273a52-3b29-437d-8d6d-677a81bb562e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "neutral\n"
          ]
        }
      ],
      "source": [
        "# Printing the first 5 items of y_train\n",
        "\n",
        "for item in y_train[:5]:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igs-BsOrGI43",
        "outputId": "62f45f30-8a00-47ac-fbca-821969a4e09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3408, 6000) <class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        }
      ],
      "source": [
        "# Importing TfidfVectorizer from scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Use unigram & bi-gram tf*idf features\n",
        "# max_features=6000: Limiting the maximum number of features to 6000\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features = 6000,\n",
        "                             sublinear_tf=True)\n",
        "\n",
        "# Transforming the tokenized text data into TF-IDF features for training set\n",
        "X_train_tfidf = vectorizer.fit_transform([\" \".join(x) for x in\n",
        "                                          X_train])\n",
        "\n",
        "# Transforming the tokenized text data into TF-IDF features for validation set\n",
        "X_val_tfidf = vectorizer.transform([\" \".join(x) for x in\n",
        "                                    X_val])\n",
        "print(X_train_tfidf.shape, type(X_train_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES9VGR8-GI43"
      },
      "outputs": [],
      "source": [
        "#Reducing the number of dimensions from 5000 to 500\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=1000, random_state=4321)\n",
        "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
        "X_val_svd = svd.transform(X_val_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGcngnSfGI43"
      },
      "source": [
        "## Logistic Regression with and without SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMU6Ka3hGI43"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression with SVD\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf = LogisticRegression(solver=\"liblinear\")\n",
        "clf.fit(X_train_svd, y_train)\n",
        "\n",
        "predictions = clf.predict(X_val_svd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKchwpnIGI44",
        "outputId": "b503dffe-8e04-4c75-cbf6-5000b9468835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.55      0.60       426\n",
            "     neutral       0.59      0.67      0.63       552\n",
            "    positive       0.74      0.74      0.74       483\n",
            "\n",
            "    accuracy                           0.66      1461\n",
            "   macro avg       0.67      0.65      0.66      1461\n",
            "weighted avg       0.66      0.66      0.66      1461\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_val, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyOTnvULGI44",
        "outputId": "db166669-c45a-49c1-a5ef-70f7be7edbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.68      0.62      0.65       426\n",
            "     neutral       0.62      0.67      0.64       552\n",
            "    positive       0.75      0.73      0.74       483\n",
            "\n",
            "    accuracy                           0.68      1461\n",
            "   macro avg       0.68      0.68      0.68      1461\n",
            "weighted avg       0.68      0.68      0.68      1461\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Logistic Regression Without SVD\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "clf = LogisticRegression(solver=\"liblinear\")\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "predictions = clf.predict(X_val_tfidf)\n",
        "# print(classification_report(y_val, predictions,\n",
        "#                             target_names=df.LABEL))\n",
        "\n",
        "print(classification_report(y_val, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7E5YwBCGI44"
      },
      "source": [
        "## MLP classifier in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu4mRBshGI44"
      },
      "source": [
        "### 1-Hot Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bUUcETPGI44",
        "outputId": "bf88e311-4383-475d-ea57-ef961b4d3045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 0  Category:  negative\n",
            "Index: 1  Category:  neutral\n",
            "Index: 2  Category:  positive\n",
            "-----------------------------------\n",
            "Label index: negative | 1-hot vector:  [1, 0, 0]\n",
            "Label index: positive | 1-hot vector:  [0, 0, 1]\n",
            "Label index: neutral | 1-hot vector:  [0, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "y_train_1_hot = pd.get_dummies(y_train).values.tolist()\n",
        "\n",
        "\n",
        "#1-Hot to train set\n",
        "for i in range(len(y_train_1_hot)):\n",
        "    for j in range(3):\n",
        "        if y_train_1_hot[i][j]==True:\n",
        "            y_train_1_hot[i][j]=1\n",
        "        else:\n",
        "            y_train_1_hot[i][j]=0\n",
        "\n",
        "\n",
        "\n",
        "#1-Hot to validation set\n",
        "y_val_1_hot = pd.get_dummies(y_val).values.tolist()\n",
        "\n",
        "for i in range(len(y_val_1_hot)):\n",
        "    for j in range(3):\n",
        "        if y_val_1_hot[i][j]==True:\n",
        "            y_val_1_hot[i][j]=1\n",
        "        else:\n",
        "            y_val_1_hot[i][j]=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i,name in enumerate (pd.get_dummies(y_train).columns):\n",
        "    print(\"Index:\",i,\" Category: \",name)\n",
        "\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "print(\"Label index: {} | 1-hot vector:  {}\".format(y_train[0],\n",
        "                                                   y_train_1_hot[0]))\n",
        "print(\"Label index: {} | 1-hot vector:  {}\".format(y_train[2],\n",
        "                                                   y_train_1_hot[2]))\n",
        "print(\"Label index: {} | 1-hot vector:  {}\".format(y_train.iloc[-3],\n",
        "                                                   y_train_1_hot[-3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aJWmSNFGI44"
      },
      "outputs": [],
      "source": [
        "# Convert y_train_1_hot from list to numpy array\n",
        "y_train_1_hot = np.array(y_train_1_hot)\n",
        "y_val_1_hot = np.array(y_val_1_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFLwpI3CGI45"
      },
      "source": [
        "### Custom Keras callback for calculating f1, precision, recall at the end of each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmnHYLq1GI45"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valid_data):\n",
        "        super(Metrics, self).__init__()\n",
        "        self.validation_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "\n",
        "        # Get predictions on validation data\n",
        "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
        "        val_targ = self.validation_data[1]\n",
        "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
        "        # If val_targ is 1-hot\n",
        "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
        "          val_targ = np.argmax(val_targ, -1)\n",
        "\n",
        "        _val_f1 = f1_score(val_targ, val_predict,average=\"weighted\")\n",
        "        _val_recall = recall_score(val_targ, val_predict,average=\"weighted\")\n",
        "        _val_precision = precision_score(val_targ, val_predict,average=\"weighted\")\n",
        "\n",
        "        logs['val_f1'] = _val_f1\n",
        "        logs['val_recall'] = _val_recall\n",
        "        logs['val_precision'] = _val_precision\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4LWX78WGI45"
      },
      "source": [
        "### MLP classifier in Keras using TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcK_vuyDGI45",
        "outputId": "ee85d5ad-bcab-482c-8a65-0d0957aa7df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               512512    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 644611 (2.46 MB)\n",
            "Trainable params: 644611 (2.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 1s 9ms/step\n",
            " — val_f1: 0.408584 — val_precision: 0.635815 — val_recall: 0.488022\n",
            "\n",
            "Epoch 1: val_f1 improved from -inf to 0.40858, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 6s 280ms/step - loss: 1.0942 - categorical_accuracy: 0.3753 - val_loss: 1.0795 - val_categorical_accuracy: 0.4880 - val_f1: 0.4086 - val_recall: 0.4880 - val_precision: 0.6358\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 7ms/step\n",
            " — val_f1: 0.504856 — val_precision: 0.680537 — val_recall: 0.566051\n",
            "\n",
            "Epoch 2: val_f1 improved from 0.40858 to 0.50486, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 2s 131ms/step - loss: 1.0601 - categorical_accuracy: 0.5229 - val_loss: 1.0376 - val_categorical_accuracy: 0.5661 - val_f1: 0.5049 - val_recall: 0.5661 - val_precision: 0.6805\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.611024 — val_precision: 0.668640 — val_recall: 0.625599\n",
            "\n",
            "Epoch 3: val_f1 improved from 0.50486 to 0.61102, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 1s 102ms/step - loss: 0.9693 - categorical_accuracy: 0.6769 - val_loss: 0.9220 - val_categorical_accuracy: 0.6256 - val_f1: 0.6110 - val_recall: 0.6256 - val_precision: 0.6686\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.677245 — val_precision: 0.677520 — val_recall: 0.678303\n",
            "\n",
            "Epoch 4: val_f1 improved from 0.61102 to 0.67724, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 1s 85ms/step - loss: 0.7603 - categorical_accuracy: 0.7814 - val_loss: 0.7655 - val_categorical_accuracy: 0.6783 - val_f1: 0.6772 - val_recall: 0.6783 - val_precision: 0.6775\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.679506 — val_precision: 0.680399 — val_recall: 0.678987\n",
            "\n",
            "Epoch 5: val_f1 improved from 0.67724 to 0.67951, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 0.5309 - categorical_accuracy: 0.8239 - val_loss: 0.7159 - val_categorical_accuracy: 0.6790 - val_f1: 0.6795 - val_recall: 0.6790 - val_precision: 0.6804\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.678909 — val_precision: 0.678503 — val_recall: 0.679671\n",
            "\n",
            "Epoch 6: val_f1 did not improve from 0.67951\n",
            "14/14 [==============================] - 2s 130ms/step - loss: 0.3974 - categorical_accuracy: 0.8624 - val_loss: 0.7422 - val_categorical_accuracy: 0.6797 - val_f1: 0.6789 - val_recall: 0.6797 - val_precision: 0.6785\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.681240 — val_precision: 0.684609 — val_recall: 0.680356\n",
            "\n",
            "Epoch 7: val_f1 improved from 0.67951 to 0.68124, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.2969 - categorical_accuracy: 0.8994 - val_loss: 0.7786 - val_categorical_accuracy: 0.6804 - val_f1: 0.6812 - val_recall: 0.6804 - val_precision: 0.6846\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 1s 8ms/step\n",
            " — val_f1: 0.692170 — val_precision: 0.696256 — val_recall: 0.691307\n",
            "\n",
            "Epoch 8: val_f1 improved from 0.68124 to 0.69217, saving model to checkpoints/tfidf_mlp.weights.h5\n",
            "14/14 [==============================] - 2s 135ms/step - loss: 0.2397 - categorical_accuracy: 0.9252 - val_loss: 0.8166 - val_categorical_accuracy: 0.6913 - val_f1: 0.6922 - val_recall: 0.6913 - val_precision: 0.6963\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 6ms/step\n",
            " — val_f1: 0.686061 — val_precision: 0.686580 — val_recall: 0.687201\n",
            "\n",
            "Epoch 9: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 2s 138ms/step - loss: 0.1940 - categorical_accuracy: 0.9437 - val_loss: 0.8706 - val_categorical_accuracy: 0.6872 - val_f1: 0.6861 - val_recall: 0.6872 - val_precision: 0.6866\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 1s 13ms/step\n",
            " — val_f1: 0.679756 — val_precision: 0.680109 — val_recall: 0.679671\n",
            "\n",
            "Epoch 10: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 0.1674 - categorical_accuracy: 0.9498 - val_loss: 0.9068 - val_categorical_accuracy: 0.6797 - val_f1: 0.6798 - val_recall: 0.6797 - val_precision: 0.6801\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.673978 — val_precision: 0.678024 — val_recall: 0.672827\n",
            "\n",
            "Epoch 11: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 0.1365 - categorical_accuracy: 0.9636 - val_loss: 0.9551 - val_categorical_accuracy: 0.6728 - val_f1: 0.6740 - val_recall: 0.6728 - val_precision: 0.6780\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.680551 — val_precision: 0.680256 — val_recall: 0.681040\n",
            "\n",
            "Epoch 12: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.1035 - categorical_accuracy: 0.9792 - val_loss: 0.9935 - val_categorical_accuracy: 0.6810 - val_f1: 0.6806 - val_recall: 0.6810 - val_precision: 0.6803\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.674775 — val_precision: 0.675611 — val_recall: 0.674880\n",
            "\n",
            "Epoch 13: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0968 - categorical_accuracy: 0.9762 - val_loss: 1.0361 - val_categorical_accuracy: 0.6749 - val_f1: 0.6748 - val_recall: 0.6749 - val_precision: 0.6756\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.679358 — val_precision: 0.680077 — val_recall: 0.678987\n",
            "\n",
            "Epoch 14: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 0.0731 - categorical_accuracy: 0.9865 - val_loss: 1.0672 - val_categorical_accuracy: 0.6790 - val_f1: 0.6794 - val_recall: 0.6790 - val_precision: 0.6801\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676049 — val_precision: 0.676757 — val_recall: 0.676249\n",
            "\n",
            "Epoch 15: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0610 - categorical_accuracy: 0.9871 - val_loss: 1.1062 - val_categorical_accuracy: 0.6762 - val_f1: 0.6760 - val_recall: 0.6762 - val_precision: 0.6768\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.677169 — val_precision: 0.678485 — val_recall: 0.676934\n",
            "\n",
            "Epoch 16: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0582 - categorical_accuracy: 0.9877 - val_loss: 1.1371 - val_categorical_accuracy: 0.6769 - val_f1: 0.6772 - val_recall: 0.6769 - val_precision: 0.6785\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.678589 — val_precision: 0.678851 — val_recall: 0.678987\n",
            "\n",
            "Epoch 17: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0524 - categorical_accuracy: 0.9897 - val_loss: 1.1543 - val_categorical_accuracy: 0.6790 - val_f1: 0.6786 - val_recall: 0.6790 - val_precision: 0.6789\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.679077 — val_precision: 0.679657 — val_recall: 0.678987\n",
            "\n",
            "Epoch 18: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 0.0494 - categorical_accuracy: 0.9891 - val_loss: 1.1660 - val_categorical_accuracy: 0.6790 - val_f1: 0.6791 - val_recall: 0.6790 - val_precision: 0.6797\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676875 — val_precision: 0.678457 — val_recall: 0.676934\n",
            "\n",
            "Epoch 19: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0462 - categorical_accuracy: 0.9891 - val_loss: 1.1947 - val_categorical_accuracy: 0.6769 - val_f1: 0.6769 - val_recall: 0.6769 - val_precision: 0.6785\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.678221 — val_precision: 0.678660 — val_recall: 0.678303\n",
            "\n",
            "Epoch 20: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0432 - categorical_accuracy: 0.9912 - val_loss: 1.2121 - val_categorical_accuracy: 0.6783 - val_f1: 0.6782 - val_recall: 0.6783 - val_precision: 0.6787\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.679224 — val_precision: 0.678998 — val_recall: 0.679671\n",
            "\n",
            "Epoch 21: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0434 - categorical_accuracy: 0.9924 - val_loss: 1.2367 - val_categorical_accuracy: 0.6797 - val_f1: 0.6792 - val_recall: 0.6797 - val_precision: 0.6790\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675357 — val_precision: 0.675400 — val_recall: 0.675565\n",
            "\n",
            "Epoch 22: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 0.0381 - categorical_accuracy: 0.9927 - val_loss: 1.2430 - val_categorical_accuracy: 0.6756 - val_f1: 0.6754 - val_recall: 0.6756 - val_precision: 0.6754\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.678436 — val_precision: 0.679127 — val_recall: 0.678303\n",
            "\n",
            "Epoch 23: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0389 - categorical_accuracy: 0.9915 - val_loss: 1.2519 - val_categorical_accuracy: 0.6783 - val_f1: 0.6784 - val_recall: 0.6783 - val_precision: 0.6791\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.680216 — val_precision: 0.680966 — val_recall: 0.680356\n",
            "\n",
            "Epoch 24: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 0.0285 - categorical_accuracy: 0.9947 - val_loss: 1.2740 - val_categorical_accuracy: 0.6804 - val_f1: 0.6802 - val_recall: 0.6804 - val_precision: 0.6810\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.677473 — val_precision: 0.677169 — val_recall: 0.678303\n",
            "\n",
            "Epoch 25: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0348 - categorical_accuracy: 0.9933 - val_loss: 1.2928 - val_categorical_accuracy: 0.6783 - val_f1: 0.6775 - val_recall: 0.6783 - val_precision: 0.6772\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.679132 — val_precision: 0.679818 — val_recall: 0.678987\n",
            "\n",
            "Epoch 26: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 65ms/step - loss: 0.0344 - categorical_accuracy: 0.9912 - val_loss: 1.2876 - val_categorical_accuracy: 0.6790 - val_f1: 0.6791 - val_recall: 0.6790 - val_precision: 0.6798\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.681594 — val_precision: 0.683296 — val_recall: 0.681725\n",
            "\n",
            "Epoch 27: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 0.0355 - categorical_accuracy: 0.9930 - val_loss: 1.3022 - val_categorical_accuracy: 0.6817 - val_f1: 0.6816 - val_recall: 0.6817 - val_precision: 0.6833\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.679587 — val_precision: 0.680833 — val_recall: 0.680356\n",
            "\n",
            "Epoch 28: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 0.0300 - categorical_accuracy: 0.9941 - val_loss: 1.3090 - val_categorical_accuracy: 0.6804 - val_f1: 0.6796 - val_recall: 0.6804 - val_precision: 0.6808\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.681572 — val_precision: 0.682003 — val_recall: 0.681725\n",
            "\n",
            "Epoch 29: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 0.0298 - categorical_accuracy: 0.9927 - val_loss: 1.3157 - val_categorical_accuracy: 0.6817 - val_f1: 0.6816 - val_recall: 0.6817 - val_precision: 0.6820\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676555 — val_precision: 0.677411 — val_recall: 0.676934\n",
            "\n",
            "Epoch 30: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0261 - categorical_accuracy: 0.9933 - val_loss: 1.3341 - val_categorical_accuracy: 0.6769 - val_f1: 0.6766 - val_recall: 0.6769 - val_precision: 0.6774\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.670188 — val_precision: 0.670663 — val_recall: 0.670773\n",
            "\n",
            "Epoch 31: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0269 - categorical_accuracy: 0.9938 - val_loss: 1.3470 - val_categorical_accuracy: 0.6708 - val_f1: 0.6702 - val_recall: 0.6708 - val_precision: 0.6707\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676412 — val_precision: 0.676105 — val_recall: 0.676934\n",
            "\n",
            "Epoch 32: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0297 - categorical_accuracy: 0.9935 - val_loss: 1.3547 - val_categorical_accuracy: 0.6769 - val_f1: 0.6764 - val_recall: 0.6769 - val_precision: 0.6761\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675561 — val_precision: 0.675444 — val_recall: 0.676249\n",
            "\n",
            "Epoch 33: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0270 - categorical_accuracy: 0.9950 - val_loss: 1.3611 - val_categorical_accuracy: 0.6762 - val_f1: 0.6756 - val_recall: 0.6762 - val_precision: 0.6754\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.674836 — val_precision: 0.676121 — val_recall: 0.674880\n",
            "\n",
            "Epoch 34: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 42ms/step - loss: 0.0258 - categorical_accuracy: 0.9944 - val_loss: 1.3720 - val_categorical_accuracy: 0.6749 - val_f1: 0.6748 - val_recall: 0.6749 - val_precision: 0.6761\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676850 — val_precision: 0.676797 — val_recall: 0.677618\n",
            "\n",
            "Epoch 35: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0259 - categorical_accuracy: 0.9938 - val_loss: 1.3882 - val_categorical_accuracy: 0.6776 - val_f1: 0.6769 - val_recall: 0.6776 - val_precision: 0.6768\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.671128 — val_precision: 0.671201 — val_recall: 0.671458\n",
            "\n",
            "Epoch 36: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 41ms/step - loss: 0.0257 - categorical_accuracy: 0.9941 - val_loss: 1.3866 - val_categorical_accuracy: 0.6715 - val_f1: 0.6711 - val_recall: 0.6715 - val_precision: 0.6712\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672638 — val_precision: 0.673109 — val_recall: 0.672827\n",
            "\n",
            "Epoch 37: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0299 - categorical_accuracy: 0.9930 - val_loss: 1.4021 - val_categorical_accuracy: 0.6728 - val_f1: 0.6726 - val_recall: 0.6728 - val_precision: 0.6731\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.670825 — val_precision: 0.670511 — val_recall: 0.671458\n",
            "\n",
            "Epoch 38: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 54ms/step - loss: 0.0289 - categorical_accuracy: 0.9935 - val_loss: 1.4033 - val_categorical_accuracy: 0.6715 - val_f1: 0.6708 - val_recall: 0.6715 - val_precision: 0.6705\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672108 — val_precision: 0.672359 — val_recall: 0.672827\n",
            "\n",
            "Epoch 39: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0330 - categorical_accuracy: 0.9930 - val_loss: 1.4019 - val_categorical_accuracy: 0.6728 - val_f1: 0.6721 - val_recall: 0.6728 - val_precision: 0.6724\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.670969 — val_precision: 0.671912 — val_recall: 0.671458\n",
            "\n",
            "Epoch 40: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0285 - categorical_accuracy: 0.9941 - val_loss: 1.4065 - val_categorical_accuracy: 0.6715 - val_f1: 0.6710 - val_recall: 0.6715 - val_precision: 0.6719\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.670472 — val_precision: 0.670614 — val_recall: 0.670773\n",
            "\n",
            "Epoch 41: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.0245 - categorical_accuracy: 0.9935 - val_loss: 1.4164 - val_categorical_accuracy: 0.6708 - val_f1: 0.6705 - val_recall: 0.6708 - val_precision: 0.6706\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.671257 — val_precision: 0.671083 — val_recall: 0.671458\n",
            "\n",
            "Epoch 42: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0263 - categorical_accuracy: 0.9935 - val_loss: 1.4271 - val_categorical_accuracy: 0.6715 - val_f1: 0.6713 - val_recall: 0.6715 - val_precision: 0.6711\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.673352 — val_precision: 0.672947 — val_recall: 0.674196\n",
            "\n",
            "Epoch 43: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0273 - categorical_accuracy: 0.9935 - val_loss: 1.4377 - val_categorical_accuracy: 0.6742 - val_f1: 0.6734 - val_recall: 0.6742 - val_precision: 0.6729\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.674902 — val_precision: 0.674706 — val_recall: 0.675565\n",
            "\n",
            "Epoch 44: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0236 - categorical_accuracy: 0.9935 - val_loss: 1.4349 - val_categorical_accuracy: 0.6756 - val_f1: 0.6749 - val_recall: 0.6756 - val_precision: 0.6747\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.672133 — val_precision: 0.671770 — val_recall: 0.672827\n",
            "\n",
            "Epoch 45: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 73ms/step - loss: 0.0256 - categorical_accuracy: 0.9941 - val_loss: 1.4413 - val_categorical_accuracy: 0.6728 - val_f1: 0.6721 - val_recall: 0.6728 - val_precision: 0.6718\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.672261 — val_precision: 0.672952 — val_recall: 0.672827\n",
            "\n",
            "Epoch 46: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 84ms/step - loss: 0.0240 - categorical_accuracy: 0.9944 - val_loss: 1.4450 - val_categorical_accuracy: 0.6728 - val_f1: 0.6723 - val_recall: 0.6728 - val_precision: 0.6730\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.668914 — val_precision: 0.668839 — val_recall: 0.669405\n",
            "\n",
            "Epoch 47: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 77ms/step - loss: 0.0217 - categorical_accuracy: 0.9950 - val_loss: 1.4619 - val_categorical_accuracy: 0.6694 - val_f1: 0.6689 - val_recall: 0.6694 - val_precision: 0.6688\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.669711 — val_precision: 0.669614 — val_recall: 0.670089\n",
            "\n",
            "Epoch 48: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 47ms/step - loss: 0.0210 - categorical_accuracy: 0.9947 - val_loss: 1.4765 - val_categorical_accuracy: 0.6701 - val_f1: 0.6697 - val_recall: 0.6701 - val_precision: 0.6696\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.671597 — val_precision: 0.671655 — val_recall: 0.672142\n",
            "\n",
            "Epoch 49: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 0.0248 - categorical_accuracy: 0.9947 - val_loss: 1.4859 - val_categorical_accuracy: 0.6721 - val_f1: 0.6716 - val_recall: 0.6721 - val_precision: 0.6717\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.674059 — val_precision: 0.673719 — val_recall: 0.674880\n",
            "\n",
            "Epoch 50: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0219 - categorical_accuracy: 0.9959 - val_loss: 1.4902 - val_categorical_accuracy: 0.6749 - val_f1: 0.6741 - val_recall: 0.6749 - val_precision: 0.6737\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.667722 — val_precision: 0.667936 — val_recall: 0.668036\n",
            "\n",
            "Epoch 51: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0206 - categorical_accuracy: 0.9950 - val_loss: 1.4873 - val_categorical_accuracy: 0.6680 - val_f1: 0.6677 - val_recall: 0.6680 - val_precision: 0.6679\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672043 — val_precision: 0.672062 — val_recall: 0.672827\n",
            "\n",
            "Epoch 52: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0236 - categorical_accuracy: 0.9941 - val_loss: 1.4941 - val_categorical_accuracy: 0.6728 - val_f1: 0.6720 - val_recall: 0.6728 - val_precision: 0.6721\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.674445 — val_precision: 0.674153 — val_recall: 0.674880\n",
            "\n",
            "Epoch 53: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0219 - categorical_accuracy: 0.9941 - val_loss: 1.5045 - val_categorical_accuracy: 0.6749 - val_f1: 0.6744 - val_recall: 0.6749 - val_precision: 0.6742\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675011 — val_precision: 0.674675 — val_recall: 0.675565\n",
            "\n",
            "Epoch 54: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0210 - categorical_accuracy: 0.9950 - val_loss: 1.5204 - val_categorical_accuracy: 0.6756 - val_f1: 0.6750 - val_recall: 0.6756 - val_precision: 0.6747\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672116 — val_precision: 0.671956 — val_recall: 0.672827\n",
            "\n",
            "Epoch 55: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0213 - categorical_accuracy: 0.9947 - val_loss: 1.5280 - val_categorical_accuracy: 0.6728 - val_f1: 0.6721 - val_recall: 0.6728 - val_precision: 0.6720\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.673681 — val_precision: 0.673431 — val_recall: 0.674196\n",
            "\n",
            "Epoch 56: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0204 - categorical_accuracy: 0.9950 - val_loss: 1.5252 - val_categorical_accuracy: 0.6742 - val_f1: 0.6737 - val_recall: 0.6742 - val_precision: 0.6734\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672160 — val_precision: 0.672206 — val_recall: 0.672827\n",
            "\n",
            "Epoch 57: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0191 - categorical_accuracy: 0.9950 - val_loss: 1.5360 - val_categorical_accuracy: 0.6728 - val_f1: 0.6722 - val_recall: 0.6728 - val_precision: 0.6722\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676036 — val_precision: 0.675769 — val_recall: 0.676934\n",
            "\n",
            "Epoch 58: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 0.0188 - categorical_accuracy: 0.9953 - val_loss: 1.5453 - val_categorical_accuracy: 0.6769 - val_f1: 0.6760 - val_recall: 0.6769 - val_precision: 0.6758\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.674790 — val_precision: 0.674686 — val_recall: 0.675565\n",
            "\n",
            "Epoch 59: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0189 - categorical_accuracy: 0.9962 - val_loss: 1.5565 - val_categorical_accuracy: 0.6756 - val_f1: 0.6748 - val_recall: 0.6756 - val_precision: 0.6747\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.680193 — val_precision: 0.679843 — val_recall: 0.681040\n",
            "\n",
            "Epoch 60: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.0213 - categorical_accuracy: 0.9944 - val_loss: 1.5648 - val_categorical_accuracy: 0.6810 - val_f1: 0.6802 - val_recall: 0.6810 - val_precision: 0.6798\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676585 — val_precision: 0.676446 — val_recall: 0.676934\n",
            "\n",
            "Epoch 61: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.0237 - categorical_accuracy: 0.9950 - val_loss: 1.5532 - val_categorical_accuracy: 0.6769 - val_f1: 0.6766 - val_recall: 0.6769 - val_precision: 0.6764\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.676646 — val_precision: 0.676665 — val_recall: 0.676934\n",
            "\n",
            "Epoch 62: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 63ms/step - loss: 0.0209 - categorical_accuracy: 0.9944 - val_loss: 1.5558 - val_categorical_accuracy: 0.6769 - val_f1: 0.6766 - val_recall: 0.6769 - val_precision: 0.6767\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.676174 — val_precision: 0.675993 — val_recall: 0.676934\n",
            "\n",
            "Epoch 63: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 0.0218 - categorical_accuracy: 0.9947 - val_loss: 1.5555 - val_categorical_accuracy: 0.6769 - val_f1: 0.6762 - val_recall: 0.6769 - val_precision: 0.6760\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 6ms/step\n",
            " — val_f1: 0.680333 — val_precision: 0.680290 — val_recall: 0.681040\n",
            "\n",
            "Epoch 64: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 0.0181 - categorical_accuracy: 0.9959 - val_loss: 1.5650 - val_categorical_accuracy: 0.6810 - val_f1: 0.6803 - val_recall: 0.6810 - val_precision: 0.6803\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.679650 — val_precision: 0.679588 — val_recall: 0.680356\n",
            "\n",
            "Epoch 65: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 0.0164 - categorical_accuracy: 0.9962 - val_loss: 1.5742 - val_categorical_accuracy: 0.6804 - val_f1: 0.6797 - val_recall: 0.6804 - val_precision: 0.6796\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.678776 — val_precision: 0.678815 — val_recall: 0.678987\n",
            "\n",
            "Epoch 66: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0194 - categorical_accuracy: 0.9950 - val_loss: 1.5884 - val_categorical_accuracy: 0.6790 - val_f1: 0.6788 - val_recall: 0.6790 - val_precision: 0.6788\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676507 — val_precision: 0.676616 — val_recall: 0.676934\n",
            "\n",
            "Epoch 67: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0216 - categorical_accuracy: 0.9941 - val_loss: 1.5908 - val_categorical_accuracy: 0.6769 - val_f1: 0.6765 - val_recall: 0.6769 - val_precision: 0.6766\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675242 — val_precision: 0.674943 — val_recall: 0.676249\n",
            "\n",
            "Epoch 68: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0198 - categorical_accuracy: 0.9953 - val_loss: 1.5942 - val_categorical_accuracy: 0.6762 - val_f1: 0.6752 - val_recall: 0.6762 - val_precision: 0.6749\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.673795 — val_precision: 0.673916 — val_recall: 0.674880\n",
            "\n",
            "Epoch 69: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 0.0180 - categorical_accuracy: 0.9956 - val_loss: 1.5989 - val_categorical_accuracy: 0.6749 - val_f1: 0.6738 - val_recall: 0.6749 - val_precision: 0.6739\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.673718 — val_precision: 0.673412 — val_recall: 0.674196\n",
            "\n",
            "Epoch 70: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0234 - categorical_accuracy: 0.9947 - val_loss: 1.5882 - val_categorical_accuracy: 0.6742 - val_f1: 0.6737 - val_recall: 0.6742 - val_precision: 0.6734\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.671845 — val_precision: 0.671611 — val_recall: 0.672142\n",
            "\n",
            "Epoch 71: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0194 - categorical_accuracy: 0.9959 - val_loss: 1.5859 - val_categorical_accuracy: 0.6721 - val_f1: 0.6718 - val_recall: 0.6721 - val_precision: 0.6716\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675935 — val_precision: 0.675733 — val_recall: 0.676249\n",
            "\n",
            "Epoch 72: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0187 - categorical_accuracy: 0.9950 - val_loss: 1.5858 - val_categorical_accuracy: 0.6762 - val_f1: 0.6759 - val_recall: 0.6762 - val_precision: 0.6757\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675071 — val_precision: 0.674774 — val_recall: 0.675565\n",
            "\n",
            "Epoch 73: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 0.0170 - categorical_accuracy: 0.9953 - val_loss: 1.5910 - val_categorical_accuracy: 0.6756 - val_f1: 0.6751 - val_recall: 0.6756 - val_precision: 0.6748\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672106 — val_precision: 0.672092 — val_recall: 0.672827\n",
            "\n",
            "Epoch 74: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0194 - categorical_accuracy: 0.9956 - val_loss: 1.6067 - val_categorical_accuracy: 0.6728 - val_f1: 0.6721 - val_recall: 0.6728 - val_precision: 0.6721\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.677223 — val_precision: 0.677034 — val_recall: 0.678303\n",
            "\n",
            "Epoch 75: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0180 - categorical_accuracy: 0.9953 - val_loss: 1.6064 - val_categorical_accuracy: 0.6783 - val_f1: 0.6772 - val_recall: 0.6783 - val_precision: 0.6770\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.676378 — val_precision: 0.676203 — val_recall: 0.676934\n",
            "\n",
            "Epoch 76: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 0.0193 - categorical_accuracy: 0.9950 - val_loss: 1.6114 - val_categorical_accuracy: 0.6769 - val_f1: 0.6764 - val_recall: 0.6769 - val_precision: 0.6762\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.673437 — val_precision: 0.673467 — val_recall: 0.674196\n",
            "\n",
            "Epoch 77: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.0212 - categorical_accuracy: 0.9941 - val_loss: 1.6071 - val_categorical_accuracy: 0.6742 - val_f1: 0.6734 - val_recall: 0.6742 - val_precision: 0.6735\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.675863 — val_precision: 0.675601 — val_recall: 0.676249\n",
            "\n",
            "Epoch 78: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.0217 - categorical_accuracy: 0.9941 - val_loss: 1.6118 - val_categorical_accuracy: 0.6762 - val_f1: 0.6759 - val_recall: 0.6762 - val_precision: 0.6756\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.671979 — val_precision: 0.672074 — val_recall: 0.673511\n",
            "\n",
            "Epoch 79: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0209 - categorical_accuracy: 0.9941 - val_loss: 1.6393 - val_categorical_accuracy: 0.6735 - val_f1: 0.6720 - val_recall: 0.6735 - val_precision: 0.6721\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.672150 — val_precision: 0.671977 — val_recall: 0.672827\n",
            "\n",
            "Epoch 80: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 78ms/step - loss: 0.0190 - categorical_accuracy: 0.9953 - val_loss: 1.6168 - val_categorical_accuracy: 0.6728 - val_f1: 0.6722 - val_recall: 0.6728 - val_precision: 0.6720\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 8ms/step\n",
            " — val_f1: 0.678372 — val_precision: 0.678103 — val_recall: 0.678987\n",
            "\n",
            "Epoch 81: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 2s 125ms/step - loss: 0.0194 - categorical_accuracy: 0.9947 - val_loss: 1.6244 - val_categorical_accuracy: 0.6790 - val_f1: 0.6784 - val_recall: 0.6790 - val_precision: 0.6781\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 6ms/step\n",
            " — val_f1: 0.677349 — val_precision: 0.677542 — val_recall: 0.678303\n",
            "\n",
            "Epoch 82: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 2s 131ms/step - loss: 0.0179 - categorical_accuracy: 0.9956 - val_loss: 1.6244 - val_categorical_accuracy: 0.6783 - val_f1: 0.6773 - val_recall: 0.6783 - val_precision: 0.6775\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 7ms/step\n",
            " — val_f1: 0.674713 — val_precision: 0.674527 — val_recall: 0.675565\n",
            "\n",
            "Epoch 83: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 2s 120ms/step - loss: 0.0170 - categorical_accuracy: 0.9959 - val_loss: 1.6422 - val_categorical_accuracy: 0.6756 - val_f1: 0.6747 - val_recall: 0.6756 - val_precision: 0.6745\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 7ms/step\n",
            " — val_f1: 0.674850 — val_precision: 0.674878 — val_recall: 0.675565\n",
            "\n",
            "Epoch 84: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0202 - categorical_accuracy: 0.9935 - val_loss: 1.6526 - val_categorical_accuracy: 0.6756 - val_f1: 0.6748 - val_recall: 0.6756 - val_precision: 0.6749\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.672539 — val_precision: 0.672272 — val_recall: 0.673511\n",
            "\n",
            "Epoch 85: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 2s 115ms/step - loss: 0.0187 - categorical_accuracy: 0.9953 - val_loss: 1.6539 - val_categorical_accuracy: 0.6735 - val_f1: 0.6725 - val_recall: 0.6735 - val_precision: 0.6723\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 7ms/step\n",
            " — val_f1: 0.674209 — val_precision: 0.674077 — val_recall: 0.674880\n",
            "\n",
            "Epoch 86: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 110ms/step - loss: 0.0187 - categorical_accuracy: 0.9944 - val_loss: 1.6531 - val_categorical_accuracy: 0.6749 - val_f1: 0.6742 - val_recall: 0.6749 - val_precision: 0.6741\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.674570 — val_precision: 0.674316 — val_recall: 0.675565\n",
            "\n",
            "Epoch 87: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 103ms/step - loss: 0.0217 - categorical_accuracy: 0.9953 - val_loss: 1.6502 - val_categorical_accuracy: 0.6756 - val_f1: 0.6746 - val_recall: 0.6756 - val_precision: 0.6743\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.674027 — val_precision: 0.673676 — val_recall: 0.674880\n",
            "\n",
            "Epoch 88: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.0200 - categorical_accuracy: 0.9944 - val_loss: 1.6457 - val_categorical_accuracy: 0.6749 - val_f1: 0.6740 - val_recall: 0.6749 - val_precision: 0.6737\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672251 — val_precision: 0.671925 — val_recall: 0.672827\n",
            "\n",
            "Epoch 89: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0183 - categorical_accuracy: 0.9956 - val_loss: 1.6603 - val_categorical_accuracy: 0.6728 - val_f1: 0.6723 - val_recall: 0.6728 - val_precision: 0.6719\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.674693 — val_precision: 0.674436 — val_recall: 0.675565\n",
            "\n",
            "Epoch 90: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 79ms/step - loss: 0.0190 - categorical_accuracy: 0.9950 - val_loss: 1.6396 - val_categorical_accuracy: 0.6756 - val_f1: 0.6747 - val_recall: 0.6756 - val_precision: 0.6744\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.675882 — val_precision: 0.675935 — val_recall: 0.676934\n",
            "\n",
            "Epoch 91: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 64ms/step - loss: 0.0179 - categorical_accuracy: 0.9956 - val_loss: 1.6636 - val_categorical_accuracy: 0.6769 - val_f1: 0.6759 - val_recall: 0.6769 - val_precision: 0.6759\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.674214 — val_precision: 0.674294 — val_recall: 0.675565\n",
            "\n",
            "Epoch 92: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 76ms/step - loss: 0.0172 - categorical_accuracy: 0.9956 - val_loss: 1.6804 - val_categorical_accuracy: 0.6756 - val_f1: 0.6742 - val_recall: 0.6756 - val_precision: 0.6743\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.672865 — val_precision: 0.672635 — val_recall: 0.673511\n",
            "\n",
            "Epoch 93: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 75ms/step - loss: 0.0177 - categorical_accuracy: 0.9950 - val_loss: 1.6528 - val_categorical_accuracy: 0.6735 - val_f1: 0.6729 - val_recall: 0.6735 - val_precision: 0.6726\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672112 — val_precision: 0.671954 — val_recall: 0.672827\n",
            "\n",
            "Epoch 94: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.0190 - categorical_accuracy: 0.9950 - val_loss: 1.6568 - val_categorical_accuracy: 0.6728 - val_f1: 0.6721 - val_recall: 0.6728 - val_precision: 0.6720\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.672232 — val_precision: 0.672113 — val_recall: 0.672827\n",
            "\n",
            "Epoch 95: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.0186 - categorical_accuracy: 0.9950 - val_loss: 1.6778 - val_categorical_accuracy: 0.6728 - val_f1: 0.6722 - val_recall: 0.6728 - val_precision: 0.6721\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.677096 — val_precision: 0.676919 — val_recall: 0.678303\n",
            "\n",
            "Epoch 96: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 57ms/step - loss: 0.0195 - categorical_accuracy: 0.9938 - val_loss: 1.6930 - val_categorical_accuracy: 0.6783 - val_f1: 0.6771 - val_recall: 0.6783 - val_precision: 0.6769\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.678425 — val_precision: 0.678408 — val_recall: 0.679671\n",
            "\n",
            "Epoch 97: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.0181 - categorical_accuracy: 0.9962 - val_loss: 1.7012 - val_categorical_accuracy: 0.6797 - val_f1: 0.6784 - val_recall: 0.6797 - val_precision: 0.6784\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.678127 — val_precision: 0.677900 — val_recall: 0.678987\n",
            "\n",
            "Epoch 98: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.0189 - categorical_accuracy: 0.9950 - val_loss: 1.7014 - val_categorical_accuracy: 0.6790 - val_f1: 0.6781 - val_recall: 0.6790 - val_precision: 0.6779\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.679978 — val_precision: 0.679972 — val_recall: 0.681040\n",
            "\n",
            "Epoch 99: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.0167 - categorical_accuracy: 0.9953 - val_loss: 1.7024 - val_categorical_accuracy: 0.6810 - val_f1: 0.6800 - val_recall: 0.6810 - val_precision: 0.6800\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.677544 — val_precision: 0.677536 — val_recall: 0.678303\n",
            "\n",
            "Epoch 100: val_f1 did not improve from 0.69217\n",
            "14/14 [==============================] - 1s 56ms/step - loss: 0.0170 - categorical_accuracy: 0.9959 - val_loss: 1.6980 - val_categorical_accuracy: 0.6783 - val_f1: 0.6775 - val_recall: 0.6783 - val_precision: 0.6775\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=X_train_svd.shape[1] , activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256,  activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3,  activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy',   # Categorical crossentropy loss function for multi-class classification\n",
        "                  optimizer=Adam(learning_rate=0.001),  # Adam optimizer with learning rate of 0.001\n",
        "                  metrics=[CategoricalAccuracy()])\n",
        "\n",
        "if not os.path.exists('./checkpoints'):\n",
        "  os.makedirs('./checkpoints')\n",
        "\n",
        "# Configure model checkpoint to save the best model based on validation F1 score\n",
        "checkpoint = ModelCheckpoint('checkpoints/tfidf_mlp.weights.h5',\n",
        "                                                monitor='val_f1',\n",
        "                                                mode='max', verbose=2,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=True)\n",
        "\n",
        "history = model.fit(X_train_svd, y_train_1_hot,\n",
        "              validation_data=(X_val_svd, y_val_1_hot),\n",
        "              batch_size=256,  # Batch size\n",
        "              epochs=100,  # Number of epochs\n",
        "              shuffle=True,\n",
        "              callbacks=[Metrics(valid_data=(X_val_svd, y_val_1_hot)),\n",
        "              checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uQ22l_2GI45"
      },
      "source": [
        "### Plot model accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "z5RT1szJGI46",
        "outputId": "b46d4f01-2aac-4e32-9c6e-b35f9dc87498"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkBklEQVR4nO3dd3wUdf7H8dfuJrtJSCOkQ+hFQZo0KZ6oUVBE8SzAoYL1p2fHcqInit6JDQ4VFDt6FtBTsKAoosDB0YsKIkUpAVIoSTa97M7vjwmLkYAhbbLJ+/l4zCOb2e/MfmZE9s13vvMdm2EYBiIiIiKNiN3qAkRERETqmgKQiIiINDoKQCIiItLoKACJiIhIo6MAJCIiIo2OApCIiIg0OgpAIiIi0ugoAImIiEijowAkIiIijY4CkIj4vV27dmGz2Zg1a9ZJb7t48WJsNhuLFy8+YbtZs2Zhs9nYtWtXlWoUkfpFAUhEREQaHQUgERERaXQUgERERKTRUQASkWp79NFHsdlsbNu2jauuuoqIiAhiYmJ4+OGHMQyDlJQULrnkEsLDw4mPj2fKlCnH7CMjI4Prr7+euLg4goKC6N69O2+99dYx7bKyshg3bhwRERFERkYyduxYsrKyKqzr559/5vLLLycqKoqgoCB69+7Np59+WqPH/uKLL9KlSxdcLheJiYnceuutx9Szfft2LrvsMuLj4wkKCqJFixaMGjWK7OxsX5uFCxcyaNAgIiMjCQ0NpVOnTjz44IM1WquIHBVgdQEi0nCMHDmSU089lSeffJL58+fzj3/8g6ioKF5++WXOOeccnnrqKd59913uvfde+vTpw5/+9CcACgoKGDx4MDt27OC2226jTZs2fPjhh4wbN46srCzuvPNOAAzD4JJLLmHZsmXcfPPNnHrqqcydO5exY8ceU8vmzZsZOHAgzZs354EHHqBJkyZ88MEHjBgxgo8++ohLL7202sf76KOPMmnSJJKTk7nlllvYunUrL730EmvWrGH58uUEBgZSXFzMkCFDKCoq4vbbbyc+Pp59+/bx+eefk5WVRUREBJs3b+aiiy6iW7duPPbYY7hcLnbs2MHy5curXaOIHIchIlJNjzzyiAEYN910k29daWmp0aJFC8NmsxlPPvmkb31mZqYRHBxsjB071rdu2rRpBmC88847vnXFxcVG//79jdDQUMPtdhuGYRjz5s0zAOPpp58u9zlnnnmmARhvvvmmb/25555rdO3a1SgsLPSt83q9xoABA4wOHTr41n333XcGYHz33XcnPMY333zTAIydO3cahmEYGRkZhtPpNM4//3zD4/H42k2fPt0AjDfeeMMwDMPYsGGDARgffvjhcff9r3/9ywCMAwcOnLAGEak5ugQmIjXmhhtu8L12OBz07t0bwzC4/vrrfesjIyPp1KkTv/76q2/dF198QXx8PKNHj/atCwwM5I477iA3N5clS5b42gUEBHDLLbeU+5zbb7+9XB2HDx/m22+/5corryQnJ4eDBw9y8OBBDh06xJAhQ9i+fTv79u2r1rF+8803FBcXc9ddd2G3H/2r9MYbbyQ8PJz58+cDEBERAcBXX31Ffn5+hfuKjIwE4JNPPsHr9VarLhGpHAUgEakxLVu2LPd7REQEQUFBREdHH7M+MzPT9/vu3bvp0KFDuSABcOqpp/reP/IzISGB0NDQcu06depU7vcdO3ZgGAYPP/wwMTEx5ZZHHnkEMMccVceRmn7/2U6nk7Zt2/reb9OmDePHj+e1114jOjqaIUOGMGPGjHLjf0aOHMnAgQO54YYbiIuLY9SoUXzwwQcKQyK1SGOARKTGOByOSq0DczxPbTkSHO69916GDBlSYZv27dvX2uf/3pQpUxg3bhyffPIJX3/9NXfccQeTJ09m5cqVtGjRguDgYJYuXcp3333H/PnzWbBgAXPmzOGcc87h66+/Pu45FJGqUw+QiFiuVatWbN++/Zgej59//tn3/pGfqamp5Obmlmu3devWcr+3bdsWMC+jJScnV7iEhYVVu+aKPru4uJidO3f63j+ia9eu/P3vf2fp0qX897//Zd++fcycOdP3vt1u59xzz2Xq1Kn89NNP/POf/+Tbb7/lu+++q1adIlIxBSARsdyFF15IWloac+bM8a0rLS3lhRdeIDQ0lLPOOsvXrrS0lJdeesnXzuPx8MILL5TbX2xsLIMHD+bll18mNTX1mM87cOBAtWtOTk7G6XTy/PPPl+vNev3118nOzmbYsGEAuN1uSktLy23btWtX7HY7RUVFgDlm6fd69OgB4GsjIjVLl8BExHI33XQTL7/8MuPGjWPdunW0bt2a//znPyxfvpxp06b5emuGDx/OwIEDeeCBB9i1axedO3fm448/Ljee5ogZM2YwaNAgunbtyo033kjbtm1JT09nxYoV7N27l++//75aNcfExDBhwgQmTZrE0KFDufjii9m6dSsvvvgiffr04aqrrgLg22+/5bbbbuOKK66gY8eOlJaW8u9//xuHw8Fll10GwGOPPcbSpUsZNmwYrVq1IiMjgxdffJEWLVowaNCgatUpIhVTABIRywUHB7N48WIeeOAB3nrrLdxuN506deLNN99k3LhxvnZ2u51PP/2Uu+66i3feeQebzcbFF1/MlClT6NmzZ7l9du7cmbVr1zJp0iRmzZrFoUOHiI2NpWfPnkycOLFG6n700UeJiYlh+vTp3H333URFRXHTTTfxxBNPEBgYCED37t0ZMmQIn332Gfv27SMkJITu3bvz5ZdfcsYZZwBw8cUXs2vXLt544w0OHjxIdHQ0Z511FpMmTfLdRSYiNctm1OZIRBEREZF6SGOAREREpNFRABIREZFGRwFIREREGh0FIBEREWl0FIBERESk0VEAEhERkUZH8wBVwOv1sn//fsLCwrDZbFaXIyIiIpVgGAY5OTkkJiYe83Dl31MAqsD+/ftJSkqyugwRERGpgpSUFFq0aHHCNgpAFTgy7X5KSgrh4eEWVyMiIiKV4Xa7SUpKqtTDjhWAKnDksld4eLgCkIiIiJ+pzPAVSwdBL126lOHDh5OYmIjNZmPevHknbD9u3DhsNtsxS5cuXXxtHn300WPeP+WUU2r5SERERMSfWBqA8vLy6N69OzNmzKhU++eee47U1FTfkpKSQlRUFFdccUW5dl26dCnXbtmyZbVRvoiIiPgpSy+BXXDBBVxwwQWVbh8REVHuycjz5s0jMzOTa6+9tly7gIAA4uPja6xOERERaVj8egzQ66+/TnJyMq1atSq3fvv27SQmJhIUFET//v2ZPHkyLVu2PO5+ioqKKCoq8v3udrtrrWYREWncvF4vxcXFVpfhlwIDA3E4HDWyL78NQPv37+fLL7/kvffeK7e+X79+zJo1i06dOpGamsqkSZM488wz2bRp03FHhU+ePJlJkybVRdkiItKIFRcXs3PnTrxer9Wl+K3IyEji4+OrPU+fzTAMo4ZqqhabzcbcuXMZMWJEpdpPnjyZKVOmsH//fpxO53HbZWVl0apVK6ZOncr1119fYZuKeoCSkpLIzs7WXWAiIlIjDMNgz549lJSUVGqiPinPMAzy8/PJyMggMjKShISEY9q43W4iIiIq9f3tlz1AhmHwxhtvcPXVV58w/ICZFDt27MiOHTuO28blcuFyuWq6TBEREZ/S0lLy8/NJTEwkJCTE6nL8UnBwMAAZGRnExsZW63KYX8bPJUuWsGPHjuP26PxWbm4uv/zyS4VJUUREpK54PB6AP/yHu5zYkfBYUlJSrf1YGoByc3PZuHEjGzduBGDnzp1s3LiRPXv2ADBhwgSuueaaY7Z7/fXX6devH6eddtox7917770sWbKEXbt28b///Y9LL70Uh8PB6NGja/VYREREKkPPmKyemjp/ll4CW7t2LWeffbbv9/HjxwMwduxYZs2aRWpqqi8MHZGdnc1HH33Ec889V+E+9+7dy+jRozl06BAxMTEMGjSIlStXEhMTU3sHIiIiIn7F0gA0ePBgTjQGe9asWcesi4iIID8//7jbzJ49uyZKExERkRrWunVr7rrrLu666y6rS/HPQdAiIiJSNwYPHkyPHj2YNm1atfe1Zs0amjRpUv2iaoACkIiIiFSZYRh4PB4CAn4XKQzv0cXmALujXg1H8cu7wERERKT2jRs3jiVLlvDcc8/5HjA+a9YsbDYbX370Lr26d8HlcrLs07f5ZeUXXDLkbOJimhHaJIQ+PbvyzQevQfpmSPsBMn6idcsWTHvycSh0g6cUm83Ga6+9xqWXXkpISAgdOnTg008/rZNjUwASERGxgGEY5BeXWrJUdg7k5557jv79+3PjjTeSum8vqb9sIinMvAvrgYcn8eSE29iy+CO6dWpLbk4OF54zgEVzZrLhq/cZOngAw6+9iz37Us2dlRaZvUFF2XD4F8jZD8CkSZO48sor+eGHH7jwwgsZM2YMhw8frpVz/lu6BCYiImKBghIPnSd+Zcln//TYEEKcfxwBIiIicDqdhDgdxNszIaiEnw3zOWaPTRjPeRdfAYHBgI2ojtB98CVgA2x2Hh8wjLnfrODTVb9y2y3nQUkB2B1me4cLAs35fMaNG+ebquaJJ57g+eefZ/Xq1QwdOrS2Dh9QABIREZHj8ZZCaSEUZoO3BBxOaNIMgN7nDIeQZr6mubm5PProo8yfP5/U1FRKS0spKCgwp7NxBJqLzWFuE9cZynqhunXr5ttHkyZNCA8PJyMjo9YPTQFIRETEAsGBDn56bEjtfojXC7npgAFhCVA2iWBwYCUeIVGYDVkpZggCaBILYfEQfMD89Xd3c917770sXLiQZ599lvbt2xMcHMzll19OcXFxxfsvqyUwMPB3q2118rBYBSAREREL2Gy2Sl2GqrKSAnDvMntwAArtENHij7czDDM05Zhjd5xOFx5nOEQ0P+Fmy5cvZ9y4cVx66aWA2SO0a9euahxA7dIgaBERkYbEMCDvIBzYZoYfW1lvT94Bc/0fbeve5ws/NImhdYfOrFq7nl27dnHw4MHj9s506NCBjz/+mI0bN/L999/zl7/8pU56cqpKAUhERKSh8HogcxdkpwBecIZB7KnmpSuA7L1QlFvxtoYXsnabQQkgvDlEtODe++7D4XDQuXNnYmJijnlE1RFTp06ladOmDBgwgOHDhzNkyBBOP/30Gj/EmmIzKnsvXCPidruJiIggOzub8PBwq8sREZEGoLCwkJ07d9KmTRuCgoJObmPDgIJMKHJDaDwEVrC91wOHfoGSPMBmjvkJjTXH2hiGGYwKs8AeANEdIcBVftvMXeb+sUFkSwiJqvKx1qYTnceT+f7WGCAREZGaYhhw4GezF6XQDUU5ZqjwFENABLhOhYIsMILK7oxymoHkRE84Ly0yByMX55i/F7qhWTtw/mYQstcLh381w4/Ncez7trJQc6jIHBt0+FdoEg0lheZlspICMDyAHaJaQ1BELZyc+kUBSEREpLo8pfDTPFj+nDnrcUVCk2DgFMhxQMFvAo/NbgahAJc5R05ASNlcOYGQlwHuNMAL2CDAaQaigzuOBhXDC5k7oTjX3Nfvw88Rdgc0bQsHt5qhJ3vv794PgKZtwBVaM+eknlMAEhERqariPFj/b1g5A7LKxsYEBEHT1uAKB1cYBIWDPRDsZcEmMAQCbOApMefWMbxmIDky346PHTP4AM5QiEwy95O50+xZOvwrRLQ0e5iOXLqKaltx+DkiwGm2yd5rBp7AIAgINmsODDIDVCOhACQiIo2L1wsb34FmHaBV/6rvJ2UNfDjWvGsKICQa+v0f9Lmh4vEzhYWwc6cZjo6MXTG8UFpsXiI7cimqpABKC4Cyh4hGNIfgqKOXyaLampfECg5D9pEByTaIamMGrj/ibAIxnap+3A2EApCIiDQu3z4Gy/5lhos/vwJdLz+57Q0D1rwGCyaYPTiRLWHgXdDjL2WPhTgJNrvZ8xIYBPxm0K7XC56isjFCjmO3iWwJjgDILZsxuWnrRjFupyYpAImISOPx/Wwz/IA56PfjG807oLqPrNz2xXnw2V3w4wfm750vgYunm5e5apLdDvYThCmbzbxN3RlmBqJGMm6nJikAiYhI47BnFXx6u/l60N2QfwjWvw1z/8983EPPMUfbHtgGWz49OiHgkRljdi837/KyOeD8x+GMv574Dq7aVtPBqxFRABIRkYYvaw/MGWOOtTnlIjhnorneHgBr34BPboX8g+b4m83z4MCW4+8rNA6umAWtBtRF5VJLFIBERKRhK8qF90ebc/PEdYVLXzYvMQEMm2qGoNWvwMKJR7exB0K7syGhe9mdUWW9PM4m0G0khMXV+WFIzVIAEhGR+skwoCTfDCA2h/nTWwppP8K+tbB3LexdY85uHNsF4rtCQjfz0Q/u/bBvPexfD/s2QFG2+TTz0e+XHy9js8EFT5u3pq95DVqfaY7r6TQUgptaduj+YPDgwfTo0YNp06ZZXUqVKACJiEj9s3eteVnqwM+Va7/nf+ZyPCHNYNS75lw6v2ezwXmTzEUaDQUgERE5eV4vHNph9rAUuqHLpRAaU/39lhbDkqdg2VRzjpyKhERDi97m0ry3+UiH9M2Q+oM5C/OBn81xOs1Ph8TTzZ+xnc2ZlUXKKACJiMjxGYY5dubQDnM5uB1SN8L+jWWzD5dZ+DD0vBoG3A5NW1Xts9J/grk3mZe4ALpeAef/05xbx/AeDUTBTY+98yq+K3QfVbXPlT+Ul5fHLbfcwscff0xYWBj33ntvufeLiop46KGHeP/998nKyuK0007jqaeeYvDgwbjdbuLi4vj444+54IILfNvMnTuXa665hvT0dEJCQur6kBSARESEo3c/Ze40x8/kpII7FbJTyged3woINgcJlxaaoWjNq+YdVaddZo6jCU8wn0jeJNactO/3Ct2wbx2krDKXXcvMu7SCo+Cif0GXEbV4wPXAkTFOVggMOanb9++77z6WLFnCJ598QmxsLA8++CDr16+nR48eANx222389NNPzJ49m8TERObOncvQoUP58ccf6dChAxdddBHvvfdeuQD07rvvMmLECEvCDygAiYjIjkUw/x4z/FSo7EnizdpBVDuIPw2a94KYU81gYxiwc6k5weCv35mTBB6ZKPDI9iFRZQOZbUefN5Wbfuxlro5DYfjzjeMuq5J8eCLRms9+cP+Jnxn2G7m5ubz++uu88847nHvuuQC89dZbtGjRAoA9e/bw5ptvsmfPHhITzeO59957WbBgAW+++SZPPPEEY8aM4eqrryY/P5+QkBDcbjfz589n7ty5tXN8laAAJCLSWOWkw1cPwqb/mL+HJZgBJDzRfB2eAOEtzMcsBAYdfz82G7Q9y1z2b4BVr5hPHM9JMxfDY046WJHIlpB0BiT1hZb9Ia6LtRMLyjF++eUXiouL6devn29dVFQUnTqZzxP78ccf8Xg8dOzYsdx2RUVFNGvWDIALL7yQwMBAPv30U0aNGsVHH31EeHg4ycnJdXcgv6MAJCLS2BRkwoZ3YcnT5u3hNjv0/T8456HKPUzzRBJ7wqUvHf3dWxZ+8g6W9fYYZbMqG+ZA5bD46n2ePwsMMXtirPrsGpKbm4vD4WDdunU4HOWfWxYaak454HQ6ufzyy3nvvfcYNWoU7733HiNHjiQgwLoYogAkItIYGAakrIZ1s2Dzx+a4HYCEHjB8mhlcaoPdAaGx5iLl2WyVvgxlpXbt2hEYGMiqVato2bIlAJmZmWzbto2zzjqLnj174vF4yMjI4MwzzzzufsaMGcN5553H5s2b+fbbb/nHP/5RV4dQIQUgEZH6KHMX/PABZO+FnleZl4iqotANP8wxBydn/HR0fWwX6HsjnH7NsU8bF/mN0NBQrr/+eu677z6aNWtGbGwsDz30EPay2bQ7duzImDFjuOaaa5gyZQo9e/bkwIEDLFq0iG7dujFs2DAA/vSnPxEfH8+YMWNo06ZNuUtqVlAAEhGpLwqzzTuxvp9dflK/9W9B+2Q4+0Fz8HFlZGwxZzb+fjYU55rrAoLNO7R6jTPn0NFYG6mkZ555htzcXIYPH05YWBj33HMP2dnZvvfffPNN/vGPf3DPPfewb98+oqOjOeOMM7jooot8bWw2G6NHj+bpp59m4sSJFX1MnbIZxpFH3MoRbrebiIgIsrOzCQ/Xk3ZFpJa5U+F/z8PaN6G0oGylDdr8yRyM/OOH5kBigE4XmuElex+495k9RHkHzPZ2x9HenKw9R/cf3RH63GDOkxMUUZdHJr9RWFjIzp07adOmDUFBJxhULid0ovN4Mt/f6gESEbFK9l5Y/hysews8Rea6mFPMoNL1Sohobq4b/DdzwPIPc2DrF+byR2x2Myz1vRHanKXeHpHfUQASEalLhmFO/rf2TTPQeEvM9Un94Ky/Qbtzjg0rUW3h0plw5j2w8iUozoOIFmVLkjnA2GYzHxTq9Zg/I1uZt7GLSIUUgERE6kJRjjmoed2bRx/1ANBqEJx1v3m56496aaI7wEVTa7dOkUZCAUhEpDa5U2HFdPP28yODkR0u8zEPva+HltbeCSPSWCkAiYhUhzsV9qwwH9AZ2dK8LBXggsO/muN7Nr5nPt8KoFkH6H0tdB9tPhpCGiXde1Q9NXX+FIBERE5WTjps+RQ2z4Xd/wN++xeyzZzd+LfPuWrZHwaNhw7naTByI3ZkluTi4mKCg4MtrsZ/5eebD5ANDAys1n4UgEREKisrBb64F7Z9RbnQE98VSovNW89LC8wnqQN0ON8MPq36W1Ku1C8BAQGEhIRw4MABAgMDfRMJSuUYhkF+fj4ZGRlERkYe89iNk2VpAFq6dCnPPPMM69atIzU1lblz5zJixIjjtl+8eDFnn332MetTU1OJjz/6PJkZM2bwzDPPkJaWRvfu3XnhhRfo27eKs6iKiBiGORfP/HvNZ2cBNO8NXS6FzpdAZNLRdnkHzSAUHGk+PV2kjM1mIyEhgZ07d7J7926ry/FbkZGR5b7zq8rSAJSXl0f37t257rrr+POf/1zp7bZu3VpugqPY2KPPmJkzZw7jx49n5syZ9OvXj2nTpjFkyBC2bt1arp2ISKXkH4b5483LXQAt+sAlL0JMx2Pb2mwQGmMuIhVwOp106NCB4uJiq0vxS4GBgdXu+TnC0gB0wQUXcMEFF5z0drGxsURGRlb43tSpU7nxxhu59tprAZg5cybz58/njTfe4IEHHqhOuSLSmJQWw6aPYNEk85KWPQDOegAG3Q0OjR6QqrPb7ZoJuh7wywuQPXr0ICEhgfPOO4/ly5f71hcXF7Nu3TqSk5N96+x2O8nJyaxYseK4+ysqKsLtdpdbRKSRKsw27956rjvMu9kMP806wPUL4az7FH5EGgi/+j85ISGBmTNn0rt3b4qKinjttdcYPHgwq1at4vTTT+fgwYN4PB7i4uLKbRcXF8fPP/983P1OnjyZSZMm1Xb5IlJfeUrMW9l/ng8b3oXiHHN9aDz0+z/odzM4Q6ytUURqlF8FoE6dOtGpUyff7wMGDOCXX37hX//6F//+97+rvN8JEyYwfvx43+9ut5ukpKRq1SoiFit0Q/omSP3BnHk5YzMEhpiPiIhsaS4YsH0h/PItFP2m5zfmVBhwO3S93JzTR0QaHL8KQBXp27cvy5YtAyA6OhqHw0F6enq5Nunp6SccMe5yuXC59JeciN8rKYSf5sHaNyBlVcVtdi+veH1ItHnb+ml/hvbJmq9HpIHz+wC0ceNGEhLMB/45nU569erFokWLfLfTe71eFi1axG233WZhlSJSqw7/aoaeDe9CweGj68ObQ3w3SOgGcaeZMzJn7jJvU8/aDSUF5jO4OgyB5qeDvWbuLhGR+s/SAJSbm8uOHTt8v+/cuZONGzcSFRVFy5YtmTBhAvv27ePtt98GYNq0abRp04YuXbpQWFjIa6+9xrfffsvXX3/t28f48eMZO3YsvXv3pm/fvkybNo28vDzfXWEi0oAU5cCix2H1K/gmJgxvAb3GQc8xEJ5oZXUiUo9ZGoDWrl1bbmLDI+Nwxo4dy6xZs0hNTWXPnj2+94uLi7nnnnvYt28fISEhdOvWjW+++abcPkaOHMmBAweYOHEiaWlp9OjRgwULFhwzMFpE/NzWBTD/HnDvNX9vnwx9bjAvY6knR0T+gM3QU9mO4Xa7iYiIIDs7u9yEiyJSD+RmwJf3H52YsGlruGgatDt2lngRaVxO5vvb78cAiUgjsu1rc26e/ENgc0D/W2HwBN2iLiInTQFIROq/0mJzRuYV083f47rCJdMhsYelZYmI/1IAEpH6LXMX/Oc62LfO/L3v/8H5j2t+HhGpFgUgEak/Sovg4DY4sBUO/AwZW2DnUnOSwqAI8yGkp15kdZUi0gAoAIlI7fN6Ydd/oSQfIpIgMskMNIYBB7fDL4tgxzewazmUFhy7fYu+cPnrZbM3i4hUnwKQiNSe0iL4YQ787wWzZ+e3giIgIBhy045dH3MqxHSC2FPNpdUgPYRURGqU/kYRkZpXmG3OzLxy5tGA4wo3b1nPToGCTLMN2eBwQsv+5jw+7c+F2M56DIWI1DoFIBGpOTnpsPJFM/wcebhoWCL0/yucPhaCyublKMotC0JZ5mMqnE0sK1lEGicFIBGpvsO/mpe5NrwLniJzXcwpMPBOOO1yCHCWb+8KNS9tiYhYRAFIRKrGMGDXMlg1E7Z+AYbXXN+iDwwaDx2Hgt1ubY0iIsehACQiJ6fQDT/Ng1UvQ/qmo+vbnQtnjodWAzWGR0TqPQUgkcbK64GUVeaztYpyji6G17wTKyjc/BkYbN6qvn+DuRzcju/J64Eh0H2UOTlh7CmWHo6IyMlQABJpjA7ugHm3wN7VVds+qi30uhZOvxqCm9ZsbSIidUABSKQx8Xph9cvwzSRzwkFnKMR3BVeYeZu6K8y8fFXoNm9TL8w2e4Wi2kBiT3NJ6AGhMVYfiYhItSgAiTREh3+FzXPB4TJ7aEKizEtZS56B3cvMNm0Hw8XTzVmZRUQaGQUgkYbEMGDDv+HLB6Akr+I2gU3g/Meg9/UarCwijZYCkEhDkX8YPrsDtnxm/t6iLzRtZc66nH/Y/BlzCgydbF7SEhFpxBSARBqCX76DeX+FnP1gD4BzHoYBt4PdYXVlIiL1kgKQiL8yDNi5BP47BXYuNdc1aw+XvWYOVhYRkeNSABLxN14vbPvSDD771pnr7AHmbennTdJztUREKkEBSMQf5B2EHYtgxzfwyyLIP2SuDwiG068xL3fpbi4RkUpTABKprzJ3m4+c+OkT2Lce3+zLYM7Q3OcG6HeL5uQREakCBSCR+iT3APwwBzZ/fPTy1hHxXaF9srkk9QNHoDU1iog0AApAIvVBSQGsmA7LpkFxbtlKG7QeBF0uhU4XQniClRWKiDQoCkAiVvJ6YdN/zEdTuPea6xK6Q8+r4dSLISzO2vpERBooBSARqxzcDh/fBPvXm79HJEHyo9Dlz2C3W1qaiEhDpwAkYoWtX5rhp8htPpD0zPFwxl/N53WJiEitUwASqUteL/z3Wfjun+bvLQfAFW9CWLy1dYmINDIKQCJ1pSgH5t1y9FldfW6EIU9AgNPaukREGiEFIJHalH8YfvkWtn0FOxaaDyR1OGHYFHMCQxERsYQCkEhNMgzI2ALbvzJDT8oqMLxH3w9vAVfMgqQ+lpUoIiIKQCI1Y88q83b2bQsga0/592I7Q4fzoeMQaNEXHPrfTkTEavqbWKQ68g/D1w/DxneOrnO4oM2fzMDTcQhEtrSuPhERqZACkMiJGAb8PN8cu5PUD6I7gM1mrt88F768H/IOADboNhK6jDDDj57ILiJSrykAiRxPcR7M+6v5QNIjgpuaQchTYj6VHSC6E1z8ArTsZ0mZIiJy8hSARCqSlQKz/wJpP4A9EJqfDqnfmz1B2xaYbeyBcOY95iSGAS5r6xURkZOiACTye3tWwZwx5qWtkGgY+W9oNQBKiyHtR/POrpz90GMMxJ5qdbUiIlIFCkAiv/XDB/DJreAphriuMPq9o4OYA5zQope5iIiIX1MAEjli3Sz47C7AMJ/EPuIlcIVaXJSIiNQGSx85vXTpUoYPH05iYiI2m4158+adsP3HH3/MeeedR0xMDOHh4fTv35+vvvqqXJtHH30Um81WbjnllFNq8SikQVj1Cnx2J2BA35vgircUfkREGjBLA1BeXh7du3dnxowZlWq/dOlSzjvvPL744gvWrVvH2WefzfDhw9mwYUO5dl26dCE1NdW3LFu2rDbKl4Zi+fPw5X3m6wG3wwVPg93S/zVERKSWWXoJ7IILLuCCCy6odPtp06aV+/2JJ57gk08+4bPPPqNnz56+9QEBAcTH6+na8gc8JfDfKbB4svn7n+6Dsx8y5/kREZEGza/HAHm9XnJycoiKiiq3fvv27SQmJhIUFET//v2ZPHkyLVsefzbeoqIiioqKfL+73e5aq1nqgYPbYcO/YeP7kJdhrjvn72YAEhGRRsGvA9Czzz5Lbm4uV155pW9dv379mDVrFp06dSI1NZVJkyZx5plnsmnTJsLCwircz+TJk5k0aVJdlS1WOPSL+VT2TR/BnhVH1zeJgcEToM/11tUmIiJ1zmYYhmF1EQA2m425c+cyYsSISrV/7733uPHGG/nkk09ITk4+brusrCxatWrF1KlTuf76ir/kKuoBSkpKIjs7m/Dw8JM6DqknDAN2fANbvzCDT+auo+/Z7ObDSXtebT6ryxFoWZkiIlJz3G43ERERlfr+9sseoNmzZ3PDDTfw4YcfnjD8AERGRtKxY0d27Nhx3DYulwuXSzP5NhiGAV//HVZMP7rOHggtz4D2ydDtSghPtK4+ERGxnN8FoPfff5/rrruO2bNnM2zYsD9sn5ubyy+//MLVV19dB9VJvfDfKUfDT69x0HEotB4EroovgYqISONjaQDKzc0t1zOzc+dONm7cSFRUFC1btmTChAns27ePt99+GzAve40dO5bnnnuOfv36kZaWBkBwcDAREREA3HvvvQwfPpxWrVqxf/9+HnnkERwOB6NHj677A5S6t+Y1+PZx8/WQydD/r9bWIyIi9ZKlk52sXbuWnj17+m5hHz9+PD179mTixIkApKamsmfPHl/7V155hdLSUm699VYSEhJ8y5133ulrs3fvXkaPHk2nTp248soradasGStXriQmJqZuD07q3o//gfn3mq//dJ/Cj4iIHFe9GQRdn5zMICqpJ7YvhPdHgbcU+twAFz6r+XxERBqZk/n+1nS34t8Mw5zJ+b2RZvjpegVc8IzCj4iInJDfDYIW8SnIhHl/NW91B+h6JYx4UY+xEBGRP6QAJP5p33r4cCxk7QGHEy54Cnpdq54fERGpFAUg8T9bv4QPrgFPMTRtbT65PbGH1VWJiIgfUQAS/3JgG3x0oxl+Og0zL3kFR1pdlYiI+BkFIPEfhW6Y/RcozoFWg+DKt/QYCxERqRKNFhX/4PXC3Jvh0HYIbw5XzFL4ERGRKlMAEv/w3ymwdT44XDDy3xCqiS1FRKTqFICk/tv2NXz3T/P1RVOheS9r6xEREb+nMUBSf7n3w9JnYf3bgAG9r4eeV1ldlYiINAAKQFL/5KTDsqmw9k3wFJnrOg2DoU9aW5eIiDQYCkBSfxgGrHwRFj0OpQXmupYD4JyHoPUga2sTEZEGRQFI6oeCTJh3qznQGaB5bzP4tD1bszuLiEiNUwAS6+1bBx+OO/pYiyFPmE90V/AREZFaogAk1lr9KiyYAN6SssdazILEnlZXJSIiDZwCkFjnx//AF/ear08dDpfMgKAIa2sSEZFGQQFIrHHoF/jsTvP1gDvgvMd0yUtEROqMJkKUuldaBP+5FopzodVAOPcRhR8REalTCkBS9xZOhNTvITgKLnsNHOqIFBGRuqUAJHVry+ewaqb5+tKZEJ5obT0iItIoKQBJ3cnaA5/81Xw94HboOMTaekREpNFSAJK6YRjwya1QmF02yeFEqysSEZFGTAGojqVlF2IYhtVl1L0tn8LOpRAQBJe9CgFOqysSEZFGTAGoDs1Zs4dzpizm3VV7rC6lbpUUwFd/N18PuAOi2lpbj4iINHoKQHUor8hDfrGHJ77YQsrhfKvLqTvLn4fsPRDeAgbdbXU1IiIiCkB1adyA1gxrUYynuID7//MDXm8juBSWtQeWTTVfn/84OEOsrUdERAQFoDplX/4vph++iRucC1nx6yHeXbXb6pJq39cPQ2khtBoEXS61uhoRERFAAahuhcVj8xZzh/NTIsjliS9+Zs+hBnwpbOdS+Gke2OxwwVOa7VlEROoNBaC61G0kxJ2GqzSHfzb7ioISD/f95/uGeSnMUwpf/s183fs6iD/N2npERER+QwGoLtkdkDwJgGEFn9HeeYhVOw/z9opd1tZVG5Y+DRk/QXBTOPshq6sREREpRwGorrU/F9r8CZu3mFeaLwDgyQU/cyi3yOLCatDOpbDkafP1hc9CSJS19YiIiPyOAlBds9ngvMcAaJs6nwui0yks8bL8l0MWF1ZD8g7CRzcCBvS8GrpebnVFIiIix1AAskJiTzjNDAb32t8HYEVDCEBeL8y9GXLTILqTOfBZRESkHlIAssq5D4M9kHbu1Zxp/4FVvzaAALRyBuxYaD7u4oo3wdnE6opEREQqpABklaatoe+NAEwIeJ+dB3NIdxdaW1N17FsH3zxqvh46GeK6WFqOiIjIiSgAWelP94EzlM723Zxm28VKf+0F8pTCvL+CtxQ6XwK9rrW6IhERkRNSALJSSBQk9QWgq32n/wag79+HAz+bt7wPf04THoqISL2nAGS1hB4AnGb71T8HQpcUwHdPmK/PvNcMQSIiIvWcApDVEroD0NW+i12H8knNLrC4oJO0+hXI2W8+6b3PDVZXIyIiUimWBqClS5cyfPhwEhMTsdlszJs37w+3Wbx4Maeffjoul4v27dsza9asY9rMmDGD1q1bExQURL9+/Vi9enXNF19TEnsAcIo9hUBK/esyWEEm/HeK+frsByEwyNp6REREKsnSAJSXl0f37t2ZMWNGpdrv3LmTYcOGcfbZZ7Nx40buuusubrjhBr766itfmzlz5jB+/HgeeeQR1q9fT/fu3RkyZAgZGRm1dRjVE9kKgiIJpJSOthRW/nLY6ooqb9k0KMyGmFOh+yirqxEREak0m2EY9eJJnDabjblz5zJixIjjtvnb3/7G/Pnz2bRpk2/dqFGjyMrKYsEC87ES/fr1o0+fPkyfPh0Ar9dLUlISt99+Ow888EClanG73URERJCdnU14eHjVD6qy3roYdi7hgZIbWBF5EUvuO7v2P7O63Pvh+Z5QWgijZ0OnC6yuSEREGrmT+f72qzFAK1asIDk5udy6IUOGsGLFCgCKi4tZt25duTZ2u53k5GRfm4oUFRXhdrvLLXWq7DJYV/sudh/KZ3+WH4wDWjzZDD9JZ0DHoVZXIyIiclL8KgClpaURFxdXbl1cXBxut5uCggIOHjyIx+OpsE1aWtpx9zt58mQiIiJ8S1JSUq3Uf1xld4L1ce0BqP/jgA5shQ3vmK/Pm6Tb3kVExO/4VQCqLRMmTCA7O9u3pKSk1G0BZXeCtfXsIoDS+n07vGHAl38DwwudLoSWZ1hdkYiIyEkLsLqAkxEfH096enq5denp6YSHhxMcHIzD4cDhcFTYJj4+/rj7dblcuFyuWqm5UqLagiuCgKJsOtj2sXJnmHW1/JEtn8Gv34HDCef/w+pqREREqsSveoD69+/PokWLyq1buHAh/fv3B8DpdNKrV69ybbxeL4sWLfK1qZdsNkjoBkA3x05SDhewNzPf4qIqUJwPXz1ovh54JzRrZ209IiIiVWRpAMrNzWXjxo1s3LgRMG9z37hxI3v2mGNhJkyYwDXXXONrf/PNN/Prr79y//338/PPP/Piiy/ywQcfcPfdd/vajB8/nldffZW33nqLLVu2cMstt5CXl8e119bz51OVXQYbHLYPgJW/1sPb4ZdNhewUiEiCQeOtrkZERKTKLL0EtnbtWs4+++gt3+PHm1+qY8eOZdasWaSmpvrCEECbNm2YP38+d999N8899xwtWrTgtddeY8iQIb42I0eO5MCBA0ycOJG0tDR69OjBggULjhkYXe8k9gSgm2M3YA6EvrxXCysrKu/QL7D8OfP1kCfAGWJtPSIiItVQb+YBqk/qfB4ggIM7YHovPI4gOua9StekZsy7dWDdfHZlvDcSti2AtmfD1XN155eIiNQ7DXYeoAYtqi04w3B4Cmlv20dadqHVFR21dYEZfuyBcOEzCj8iIuL3FIDqC7vdNxD6NNsuMnIKKfV4LS4K8JQeHfjc/68Q3cHaekRERGqAAlB9UjYhYjfHTrwGHMgtsrYegJ/mweFfIDgK/nSf1dWIiIjUCAWg+qTsTrCeAeZA6FSrL4MZBiz7l/n6jFvAVY/nJxIRETkJCkD1SdkzwToaO7HjtX4c0PavIX0TOEOh743W1iIiIlKDFIDqk2btIbAJQRTR1rbf+h6g/041f/a+FoKbWluLiIhIDVIAqk/sDojvCkBX207Ssi18Kvzu/0HKSvORF2fcal0dIiIitUABqL4puwx2mn2XtT1AR3p/evwFwhOsq0NERKQWKADVN/HmrfCdbbutGwOU+gPsWAg2u/nMLxERkQZGAai+ie4IQGt7mnU9QEfu/OpyqTlBo4iISAOjAFTflD1hPcF2GLc7C6+3jp9UcugXc+4fgEF3n7CpiIiIv6pSAHrrrbeYP3++7/f777+fyMhIBgwYwO7du2usuEYpJAqj7I6rFkYaB/PqeDLEhRPB8EKH830DskVERBqaKgWgJ554guDgYABWrFjBjBkzePrpp4mOjubuu9VrUF22KLMXqLUtrW7HAW35DH7+HOwBkPxo3X2uiIhIHQuoykYpKSm0b98egHnz5nHZZZdx0003MXDgQAYPHlyT9TVOzdrDvrW0saWSml1ItxZ18JmF2fBF2aMuBt4JcV3q4ENFRESsUaUeoNDQUA4dOgTA119/zXnnnQdAUFAQBQUWzl3TUJSNA2pTlz1Aix6HnFRz0LOe+SUiIg1clXqAzjvvPG644QZ69uzJtm3buPDCCwHYvHkzrVu3rsn6GqeyANTansaiughAKathzWvm64v+BYHBtf+ZIiIiFqpSD9CMGTPo378/Bw4c4KOPPqJZs2YArFu3jtGjR9dogY1S1G97gGq5R81TAp/dCRjQ/S/QdnDtfp6IiEg9UKUeoMjISKZPn37M+kmTJlW7IMHXAxRtc5OVeah2P+t/z0PGTxAcBef/o3Y/S0REpJ6oUg/QggULWLZsme/3GTNm0KNHD/7yl7+QmZlZY8U1Wq4wioNjAHBm76y9z8k7BEueMV8PnQxNmtXeZ4mIiNQjVQpA9913H263G4Aff/yRe+65hwsvvJCdO3cyfvz4Gi2wsfI2NWdgDs3bhWHU0mSIG96G0gJI6A7dRtbOZ4iIiNRDVboEtnPnTjp37gzARx99xEUXXcQTTzzB+vXrfQOipXoCY9rD/lUkeVPJzC8hqomzZj/AUwprXjdf9/0/sNlqdv8iIiL1WJV6gJxOJ/n5+QB88803nH/++QBERUX5eoakehwxHYAjzwSrhYHQ2xZAdoo59ue0P9f8/kVEROqxKvUADRo0iPHjxzNw4EBWr17NnDlzANi2bRstWtTFrH2NgO9OsFTSsgvpkhhRs/tf/Yr5s9dY3fYuIiKNTpV6gKZPn05AQAD/+c9/eOmll2jevDkAX375JUOHDq3RAhut30yGmJpVwz1AGT/DziVgs0Pv62p23yIiIn6gSj1ALVu25PPPPz9m/b/+9a9qFyRlosxB0BG2fLIPpQOta27fa141f3a6ECJb1tx+RURE/ESVAhCAx+Nh3rx5bNmyBYAuXbpw8cUX43A4aqy4Ri0wmBxXHGFF6XgPbgf61cx+C7Nh4/vm67431cw+RURE/EyVAtCOHTu48MIL2bdvH506dQJg8uTJJCUlMX/+fNq1a1ejRTZWBWFtCCtKJ7Am5wLa+D6U5EF0J2jzp5rbr4iIiB+p0higO+64g3bt2pGSksL69etZv349e/bsoU2bNtxxxx01XWOj5Y06OhdQzezQe/TyV98bdeu7iIg0WlXqAVqyZAkrV64kKirKt65Zs2Y8+eSTDBw4sMaKa+wCYzrANogu2othGNiqG1h+/RYO7QBXOHTXM9tERKTxqlIPkMvlIicn55j1ubm5OJ01PGFfIxaaeAoASUYq7sLS6u3M64Vv/2m+7vEXcIVWszoRERH/VaUAdNFFF3HTTTexatUqDMPAMAxWrlzJzTffzMUXX1zTNTZarriyyRBtaaRV91b4DW/D/vXgDINBd9dAdSIiIv6rSgHo+eefp127dvTv35+goCCCgoIYMGAA7du3Z9q0aTVcYiMW2QoPdprYijiUtrvq+8k/DN88ar4++0EIi6+R8kRERPxVlcYARUZG8sknn7Bjxw7fbfCnnnoq7du3r9HiGr0AJwcD4okr3U9B2jaga9X2s2gSFGRCbBfd+i4iIsJJBKA/esr7d99953s9derUqlck5WQFJxGXsx/vwR1V28HedbDuLfP1sGfBUeWpn0RERBqMSn8bbtiwoVLtqn2nkpRTENYGclZVbS4grwe+uAcwoNsoaDWgxusTERHxR5UOQL/t4ZG6423aFvZDaN6ek994/Vuwf4N52/t5j9V8cSIiIn6qSoOgpe4ExprjqqKLTjIA5R2EbyaZr8/5O4TF1XBlIiIi/ksBqJ4La27OBZTgTTPn8qmsrx6CwiyI6wq9r6+d4kRERPxUvQhAM2bMoHXr1gQFBdGvXz9Wr1593LaDBw/GZrMdswwbNszXZty4cce8P3To0Lo4lBoX3bw9RUYALkrIO1jJW+F/+Q5+mA3YYPhzGvgsIiLyO5YHoDlz5jB+/HgeeeQR1q9fT/fu3RkyZAgZGRkVtv/4449JTU31LZs2bcLhcHDFFVeUazd06NBy7d5///26OJwaFxrsYi/m5auc7f/74w1KCmB+2R17fW+EFr1qsToRERH/ZHkAmjp1KjfeeCPXXnstnTt3ZubMmYSEhPDGG29U2D4qKor4+HjfsnDhQkJCQo4JQC6Xq1y7pk2b1sXh1IqVLvP5aiHrXwHDOHHjpc/C4V8hLBHOebgOqhMREfE/lgag4uJi1q1bR3Jysm+d3W4nOTmZFStWVGofr7/+OqNGjaJJkybl1i9evJjY2Fg6derELbfcwqFDh2q09rq0vNllFBmBhB/aCLtP0AuUsQWWTzNfX/g0BIXXRXkiIiJ+x9IAdPDgQTweD3Fx5e9QiouLIy0t7Q+3X716NZs2beKGG24ot37o0KG8/fbbLFq0iKeeeoolS5ZwwQUX4PF4KtxPUVERbre73FKfBEXG86HnT+Yvy5+ruJHXC5/dCd5S6HQhnHJR3RUoIiLiZ/x6dOzrr79O165d6du3b7n1o0aN8r3u2rUr3bp1o127dixevJhzzz33mP1MnjyZSZMm1Xq9VRUbHsSrnmGMCfgW2/avIP0niOtcvtHa1yFlFQQ2gQufAU1IKSIiclyW9gBFR0fjcDhIT08vtz49PZ34+BM/sDMvL4/Zs2dz/fV/fIt327ZtiY6OZseOih8nMWHCBLKzs31LSkpK5Q+iDsSGudhtxLMhtKwX6H8vlG/w6xJY8ID5+py/Q0SLui1QRETEz1gagJxOJ7169WLRokW+dV6vl0WLFtG/f/8Tbvvhhx9SVFTEVVdd9Yefs3fvXg4dOkRCQkKF77tcLsLDw8st9UlceBAAc5yXmit+/ACy95mvM7bAnKvNS19d/gz9braoShEREf9h+V1g48eP59VXX+Wtt95iy5Yt3HLLLeTl5XHttdcCcM011zBhwoRjtnv99dcZMWIEzZo1K7c+NzeX++67j5UrV7Jr1y4WLVrEJZdcQvv27RkyZEidHFNNiw13AbCisDW0PtMMOytfhJw0ePcKKMqGlv1hxEtgt/w/qYiISL1n+RigkSNHcuDAASZOnEhaWho9evRgwYIFvoHRe/bswf67L/WtW7eybNkyvv7662P253A4+OGHH3jrrbfIysoiMTGR888/n8cffxyXy1Unx1TT4sLMHqB0dyHGiDuw7fovrJsFO5dAdgo0aw+j3oPAIGsLFRER8RM2w/ijiWUaH7fbTUREBNnZ2fXiclhhiYdTHl4AwPcTzyNi1mDI2Gy+GRINNyyEqLbWFSgiIlIPnMz3t66X+IGgQAfhQWZnXUZOEQy803wjIAhGz1b4EREROUmWXwKTyokND8JdmEtGThEdul4BRW5I6A5JfawuTURExO8oAPmJuHAXOzJySXcXmgOd+95odUkiIiJ+S5fA/ERs2UDojJwiiysRERHxfwpAfuLIrfDp7kKLKxEREfF/CkB+Qj1AIiIiNUcByE/ElfUAZagHSEREpNoUgPyEeoBERERqjgKQn4j7zRggzV0pIiJSPQpAfuJID1BhiZecolKLqxEREfFvCkB+ItjpIOzIbNAaByQiIlItCkB+JDbsyEBojQMSERGpDgUgPxIXXvZU+Bz1AImIiFSHApAfUQ+QiIhIzVAA8iO+HiAFIBERkWpRAPIjMUd6gHQJTEREpFoUgPzIkR4gXQITERGpHgUgPxKrHiAREZEaoQDkR347BkizQYuIiFSdApAfiS17HEZBiYdczQYtIiJSZQpAfiTEGUCYy5wNWneCiYiIVJ0CkJ+JCdc4IBERkepSAPIzcWG6E0xERKS6FID8TKx6gERERKpNAcjPaDZoERGR6lMA8jNH5wJSABIREakqBSA/E+vrAdIlMBERkapSAPIzR3qADqgHSEREpMoUgPxMnHqAREREqk0ByM8c6QHKL9Zs0CIiIlWlAORnmrgCCPXNBq1eIBERkapQAPJDvjvBdCu8iIhIlSgA+SFNhigiIlI9CkB+KFaPwxAREakWBSA/FFfWA6QxQCIiIlWjAOSHfD1AmgtIRESkShSA/FCseoBERESqRQHID8WXTYa4L6vA4kpERET8kwKQH2ofGwrA3swC8os1GaKIiMjJqhcBaMaMGbRu3ZqgoCD69evH6tWrj9t21qxZ2Gy2cktQUFC5NoZhMHHiRBISEggODiY5OZnt27fX9mHUmWahLqJDzctg29NzLa5GRETE/1gegObMmcP48eN55JFHWL9+Pd27d2fIkCFkZGQcd5vw8HBSU1N9y+7du8u9//TTT/P8888zc+ZMVq1aRZMmTRgyZAiFhQ1nzEyneLMXaGt6jsWViIiI+B/LA9DUqVO58cYbufbaa+ncuTMzZ84kJCSEN95447jb2Gw24uPjfUtcXJzvPcMwmDZtGn//+9+55JJL6NatG2+//Tb79+9n3rx5dXBEdaNDbBgA29IUgERERE6WpQGouLiYdevWkZyc7Ftnt9tJTk5mxYoVx90uNzeXVq1akZSUxCWXXMLmzZt97+3cuZO0tLRy+4yIiKBfv34n3Ke/6RRfFoAydAlMRETkZFkagA4ePIjH4ynXgwMQFxdHWlpahdt06tSJN954g08++YR33nkHr9fLgAED2Lt3L4Bvu5PZZ1FREW63u9xS33WMUw+QiIhIVVl+Cexk9e/fn2uuuYYePXpw1lln8fHHHxMTE8PLL79c5X1OnjyZiIgI35KUlFSDFdeOjnHmGKA0dyHZ+SUWVyMiIuJfLA1A0dHROBwO0tPTy61PT08nPj6+UvsIDAykZ8+e7NixA8C33cnsc8KECWRnZ/uWlJSUkz2UOhcWFEjzyGAAtmWoF0hERORkWBqAnE4nvXr1YtGiRb51Xq+XRYsW0b9//0rtw+Px8OOPP5KQkABAmzZtiI+PL7dPt9vNqlWrjrtPl8tFeHh4ucUfHOkF2qrLYCIiIiclwOoCxo8fz9ixY+nduzd9+/Zl2rRp5OXlce211wJwzTXX0Lx5cyZPngzAY489xhlnnEH79u3JysrimWeeYffu3dxwww2AeYfYXXfdxT/+8Q86dOhAmzZtePjhh0lMTGTEiBFWHWat6BgXxndbD7BNt8KLiIicFMsD0MiRIzlw4AATJ04kLS2NHj16sGDBAt8g5j179mC3H+2oyszM5MYbbyQtLY2mTZvSq1cv/ve//9G5c2dfm/vvv5+8vDxuuukmsrKyGDRoEAsWLDhmwkR/5xsIrQAkIiJyUmyGYRhWF1HfuN1uIiIiyM7OrteXwzbty+aiF5bRNCSQ9Q+fh81ms7okERERy5zM97ff3QUmR7WPDcVmg8z8Eg7mFltdjoiIiN9QAPJjQYEOWjdrAugymIiIyMlQAPJzuhNMRETk5CkA+TkNhBYRETl5CkB+TgFIRETk5CkA+TnfQ1HTc9ENfSIiIpWjAOTnWjdrQqDDRm5RKfuzC60uR0RExC8oAPk5Z4CdttHmQGg9GV5ERKRyFIAagI5ll8G2ahyQiIhIpSgANQAdY8t6gBSAREREKkUBqAHoGK87wURERE6GAlAD0KnsVvjt6bl4vLoTTERE5I8oADUASVEhBAXaKSr1sudwvtXliIiI1HsKQA2Aw26jQ2zZQOg0t8XViIiI1H8KQA1E54RwAL7fm21xJSIiIvWfAlAD0atVUwDW7c60uBIREZH6TwGogTi9LAB9n5JFicdrcTUiIiL1mwJQA9EupgmRIYEUlXrZvF/jgERERE5EAaiBsNls9Gqpy2AiIiKVoQDUgBy5DLZeAUhEROSEFIAakN5lAWjt7sMYhiZEFBEROR4FoAakW4tIAuw20t1F7MsqsLocERGReksBqAEJdjrokmjOB6RxQCIiIsenANTAaByQiIjIH1MAamB6t4oCYN0eBSAREZHjUQBqYE5vFQnAltQc8opKrS1GRESknlIAamASIoJpHhmMx2vwfUqW1eWIiIjUSwpADdDpei6YiIjICSkANUBH5gPSOCAREZGKKQA1QL1+cyeY16sJEUVERH5PAagBOiU+jBCnA3dhKTsO5FpdjoiISL2jANQABTjs9EiKBDQOSEREpCIKQA3Ukctga3cpAImIiPyeAlADdeROsDW79GBUERGR31MAaqB6t2qKK8DOnsP5bNR8QCIiIuUoADVQYUGBDOuWAMD7q/dYXI2IiEj9ogDUgP2lb0sAPvs+FXdhicXViIiI1B8KQA1Yr1ZN6RAbSkGJh0827LO6HBERkXpDAagBs9ls/KWf2Qv07qo9GgwtIiJSpl4EoBkzZtC6dWuCgoLo168fq1evPm7bV199lTPPPJOmTZvStGlTkpOTj2k/btw4bDZbuWXo0KG1fRj10qU9m+MKsPNzWg7f7822uhwREZF6wfIANGfOHMaPH88jjzzC+vXr6d69O0OGDCEjI6PC9osXL2b06NF89913rFixgqSkJM4//3z27St/iWfo0KGkpqb6lvfff78uDqfeiQxxMqyrORj6vVW7La5GRESkfrAZFl8X6devH3369GH69OkAeL1ekpKSuP3223nggQf+cHuPx0PTpk2ZPn0611xzDWD2AGVlZTFv3rwq1eR2u4mIiCA7O5vw8PAq7aM+WbPrMFfMXEFwoINVD51LeFCg1SWJiIjUuJP5/ra0B6i4uJh169aRnJzsW2e320lOTmbFihWV2kd+fj4lJSVERUWVW7948WJiY2Pp1KkTt9xyC4cOHTruPoqKinC73eWWhqT3bwdDb9xvdTkiIiKWszQAHTx4EI/HQ1xcXLn1cXFxpKWlVWoff/vb30hMTCwXooYOHcrbb7/NokWLeOqpp1iyZAkXXHABHo+nwn1MnjyZiIgI35KUlFT1g6qHbDYbo8tuiX9Pg6FFRESsHwNUHU8++SSzZ89m7ty5BAUF+daPGjWKiy++mK5duzJixAg+//xz1qxZw+LFiyvcz4QJE8jOzvYtKSkpdXQEdefPpzfHGWBnS6pbg6FFRKTRszQARUdH43A4SE9PL7c+PT2d+Pj4E2777LPP8uSTT/L111/TrVu3E7Zt27Yt0dHR7Nixo8L3XS4X4eHh5ZaG5reDoV/9768WVyMiImItSwOQ0+mkV69eLFq0yLfO6/WyaNEi+vfvf9ztnn76aR5//HEWLFhA7969//Bz9u7dy6FDh0hISKiRuv3V/53VFoAvfkxla1qOxdWIiIhYx/JLYOPHj+fVV1/lrbfeYsuWLdxyyy3k5eVx7bXXAnDNNdcwYcIEX/unnnqKhx9+mDfeeIPWrVuTlpZGWloaubm5AOTm5nLfffexcuVKdu3axaJFi7jkkkto3749Q4YMseQY64tT4sO5sGs8hgHPf7vd6nJEREQsY3kAGjlyJM8++ywTJ06kR48ebNy4kQULFvgGRu/Zs4fU1FRf+5deeoni4mIuv/xyEhISfMuzzz4LgMPh4IcffuDiiy+mY8eOXH/99fTq1Yv//ve/uFwuS46xPrnj3A6AeoFERKRxs3weoPqooc0D9Ht/fXcdX/yYxrBuCcz4y+lWlyMiIlIj/GYeILGGeoFERKSxUwBqhDQWSEREGjsFoEZKvUAiItKYKQA1UuV6gRapF0hERBoXBaBG7Egv0PwfU/lo3V6LqxEREak7CkCN2Cnx4dx6djsAHvj4B1b8cvwHxoqIiDQkCkCN3D3ndWJYtwRKPAY3v7OOXw7kWl2SiIhIrVMAauTsdhtTruhOz5aRZBeUcN2sNRzOK7a6LBERkVqlACQEBTp49ZreJEUFs/tQPje9vZbCEo/VZYmIiNQaBSABIDrUxZvj+hAWFMDa3ZlM/GST1SWJiIjUGgUg8WkfG8bMq3pht8EHa/cyb8M+q0sSERGpFQpAUs7A9tG+2+Mfmvsjv2pQtIiINEAKQHKM28/pwBlto8gr9nDbexs0HkhERBocBSA5hsNu47lRPYlq4uSnVDeTv9hidUkiIiI1SgFIKhQXHsTUK7sD8NaK3SzYlGpxRSIiIjVHAUiOa3CnWP7vrLYA3P+fH9iXVWBxRSIiIjVDAUhO6N7zO9EjKRJ3YSn3fvA9Xq9hdUkiIiLVpgAkJxTosPOvkT0IDnSw4tdDvPm/XVaXJCIiUm0KQPKH2kQ34e8XnQrAUwt+Zlt6jsUViYiIVI8CkFTKX/q25OxOMRSXerl7zkaKS71WlyQiIlJlCkBSKTabjacu60bTkEA273fz3KJtVpckIiJSZQpAUmmx4UFM/nNXAF5a/AvzNuyjoFiTJIqIiP8JsLoA8S9DT0vgstNb8NH6vdw1ZyOuADv92zXjnFNiST41jsTIYKtLFBER+UM2wzB0X/PvuN1uIiIiyM7OJjw83Opy6p28olL+tXAbX25KKzc3UKDDxgujezL0tAQLqxMRkcbqZL6/FYAqoABUOYZhsD0jl29/zuDLTWl8n5JFoMPGK1f35uxTYq0uT0REGpmT+f7WGCCpMpvNRse4MG4+qx0f3zKA4d0TKfEY/N8761i+46DV5YmIiByXApDUCIfdxtQru3Ne5ziKS73c8NZa1uw6bHVZIiIiFVIAkhoT6LAz/S89+VPHGApKPFz75hrWKgSJiEg9pAAkNcoV4ODlq3pxRtsocotKuXzmCm5/fwO7DuZZXZqIiIiPApDUuGCng9fH9mFEj0QAPvt+P8lTl/Dg3B9JdxdaXJ2IiIjuAquQ7gKrOZv3Z/PsV1v5busBAOw2SIgIpnnTYFpEBtOiaTCd4sM5o20UzUJdFlcrIiL+TLfBV5MCUM1bvfMwz3z1M2t2ZR63Tce4UPq3bUa/ts1oFxNKUlQwIU7N1SkiIpWjAFRNCkC1JyOnkL2ZBWVLPimHC9iwJ5Of0yp+wnx0qJOkqBBaRoXQqlkTWjczf7ZqFkKzJk5sNlsdH4GIiNRXCkDVpABU9w7lFrF652FW/HqI9Xsy2XMoH3dh6Qm3CXE6SGoaQlJUMC2amoHIALyGgbfsT3W7mCb0bh1Fcz2iQ0SkwVMAqiYFoPohO7+ElMx89hw2l92H8th10Py5P/vkBlMnRATRq1VTOsWFUeI1KCrxUFTqpajUS8+WkVzSIxFXgKOWjkREROqCAlA1KQDVf4UlHvZlFZByOJ+UzAL2Hs4nu6AEm82G3QZ2m41Sr5fN+91s3u/G4z3xH/OYMBfjBrTmqn6tiAgJxDAMtqbn8N9tB1m24yDZBSU47DYcdhsBdhs2GxQUe8gv9pBXXEp+kYemTZz0aR1FvzZR9G0T5fcPhs3MK2ZLmpudB/NIiAjitMQIYsODrC5LROS4FICqSQGoYckvLmVjShbrdmWSkpmPK8CBK8BOUKADj2Ewb8M+Ust6lEKcDga2j+b7lCwycoqq9bmJEUGEBQVyZJiSzWYjPCiA9rGhdIgNpUNcGO1iQnHYbRSWeCgq9VBY4iUrv4R9Wfnsyyxgb1YBqVmFNHE5SIwMJjEymOaRwcRHBBEWFEATZ4D50xVAgN2GYRy9BGhgYLfZyhazhgM5RfyU6ubntBy2pJrhxmG3EeJ0EBzoINgZgLughJ/T3KS7jz3+mDAXXZtH0CUxnE7xYZwSH0brZk0IcBydUcMwDApKPGTll5BfXEp+sccMiyUemoY4aR8bSqhLg9tFpOYpAFWTAlDjUuLx8vkP+3l5ya/lBmMHBdrp16YZf+oYQ8uoEDxeA4/XoNTrxTDM+Y6aOAMIcTkIcTrYe7iA1bsOs+rXQ2yqRK9TXbPZ4GT/b0+KCqZtdCj7swr45UAuFR2SM8BOu5hQbEBmfjGH84opKvWecL/x4UF0iAulRdNg3AWlHMgt4lBuEQdzizEMg4iQQCKDnUSGBBIRHEhsWBBx4S7iwoOIDXPRtImToMCjQdZht5FyOJ9t6TlsS89lR0YO2QUlJEYGk9Q0hBZNg0mKCiGqiZNQ19HQCLA/q4CUwwWkZOazNzMfgKYhTiJDnDQNCSQyJJDgwACCneZ/5yOf5/EaeL0GHsPAaxi4AswQGeiw1djg/MISDwdyikjNLiTNXUhadgHp7iKCAu20aBriO7bYcBclHoPCEjNsFpZ6CHUFkBgRjN1etVpKPV4O5hZTWBZcw4MD/vC4Cks8fJ+SxYaULFwB9rKQHE5UE2eVaqgKr9fAXVhCYYmXEo+XYo+XUs+R/0Z2gp0OggIcBDvNPz/14UYKwzA4kFtEdn4JEcGBRIY4cQZomr6qUACqJgWgxskwDJbtOMgPe7Pp3iKS3q2bEhRYtXFBuUWlbEl1U1xqhiUDA8OAQ3lF7MjILfuSzmX3oTy8hhm2ggLNv5hDgwJoHmnOldQ8MpjEyCDyijzszyooWwpJzykkt7CU3KLSPwwbv2W3QZvoJpyaEM6pCeG0jzWDS0HZF2d+sYegQAed4sPoFB9Wrqcmv7iULak5bN6fzU/7zV6kbek55Bd7KvysgLKepSYuMzwEBzo4kFNU7Z61mlSVUPhHHHYbwYFmWAoNCiAsKJAwVwChrgACHOZlVIfNht1u9syZvXZH/4wczism3V1IuruQzPySatUSHOigbUwT2seG0i4mlJgwV1mocxLVxEmJx8ueQ0fH2aVkFpDhLuRAThGH84vLnRuH3UbTECdRTQLLfh5dSjwGa3cd5oe92RR7jv3zGBPmol1ME0JdAb4eWGeAnSauAF89TUOchLgcHM4tJq3s+NOyCynxeAkPDiQ8KJDwYDO4FpV4ySksJbeohNyiUrILSjiUW8zB3GIy84sr/Y8Pp8NO0yaBRDVx0ayJk4jgQLyGQWnZP3ZKPF5cAXbCg80gfmQxe0vNMBwc6CCvqJRdh8zxibsP5bMvq+CY7YKd5f8u8XoN0t2F5iX8zHwKS8qftyZOh3leys53RLD5s4krAI/XS3GpGe6KSr1l/6+Zf8ZCXA5CAs3aXIF2nA7zfNvtUFxqHlOJx9w+t6i07DyWklNYQnGpF4fdTqDDRoDDRoDdTlGpl8ISD/nFpRSUePF4vYS5zGMKDw4gIjgQw4DCsh7swhIPXsMgqomTmFAXMWFBxIS5CC7rcfd4zTDq8RokRgTTslnIyf/BPgG/C0AzZszgmWeeIS0tje7du/PCCy/Qt2/f47b/8MMPefjhh9m1axcdOnTgqaee4sILL/S9bxgGjzzyCK+++ipZWVkMHDiQl156iQ4dOlSqHgUgqSulHi8Oe/V6DEo8XvKLPJR6vdht5vgk3/4MfD0UXq9BeHBglUNdRbxeg72ZBWzPyMFhtxHVxOn7cgxxOio8ruyCEnZkmL00+7MKiQwJJDrUVbaYUxtkFxSTlV9CVn4JmfnFHMgpIt1dSEbZz+yCEopKvBSWeijxmH+FNWtiXl7rGBdGx7hQIkOc7Ms6Ot3C3sx8sgvML83fftm4AuwkRYWQVNZLZPZkmZ+blV9CdkHJbwJiaYW9YLURpH5bX3xEEPHhQcRHBBEXHkRBsYe9mfnszTR7ro4cz5HwFRRoJ7ugxHduqspht+EKsB835FYkJsxFn9ZNKfWY4+j2HM6vtXNzIoFlX+CBDhuBDjs2GxSVeCko8VBaz3pnwfzHSVhQIDmFJRX+GWuIbj27HfcNOaVG93ky39+WX4ifM2cO48ePZ+bMmfTr149p06YxZMgQtm7dSmxs7DHt//e//zF69GgmT57MRRddxHvvvceIESNYv349p512GgBPP/00zz//PG+99RZt2rTh4YcfZsiQIfz0008EBWkQp9Qfvx07U1WBDjsRIdZ0l9vtNlo2Czmpf8VFBAfSq1VTerVqWiM1HPmX+skEu1KPl7wiDyVe70nNJ2UYBsUes1fPbjMHxB+5xFRcan65HrkMlVtk/ss6t7CUnKIScgtLfT0L5r+AzfFaNhvYKAuumJff4soCT1y4i4jgwBPWZxgGecUeXAF2An/z56nE42XP4Xx+ychlx4Fcdh3M43CeeYkyK7+Ew/nFOGxl//3K5tpKahpCfIT5L/aYMBdRIU7sZWPUsvJLfNsfzi8ms+x1Zn4xpV6DHkmR9G0dRatmIeXqzSsqZVt6DrsP5VNY4jF7Lcp6CnKLSsnMLyYzv4Ts/BJyikpp1sRJXHgQ8RHmJc+gAAfuwhLcBSW4C80ei6BAu9mzFmRezgwPCqRZqJNmTVw0CzVD+IkuIZV6zP9W2QUlZOaVcCiviMz8YtwFpdjLbnQ40lNXVOrFXWgG4ewCs47CEo8vFBeUmL1Ev52jrEXTEEo9R7dzF5QeEyJtNogOdZEUFUzLqBASIoJxBth9l/COhvCj/xjIyi8mp6gUp8P8b+0s60nzeA3yiszPOPKzqPTona5FpV4Mw/BtFxhgx+mw0aSsZ/LIuXQF2Cn1GpR6vJR4zMv9TofZm3mkF9dht5Fz5LgKS8nOL8Fmw9fjFBTgwG6zcTiviAO5Rb5e3+JS8x9oR24msdvMP+tWsrwHqF+/fvTp04fp06cD4PV6SUpK4vbbb+eBBx44pv3IkSPJy8vj888/960744wz6NGjBzNnzsQwDBITE7nnnnu49957AcjOziYuLo5Zs2YxatSoP6xJPUAiIiL+52S+vy0dZVVcXMy6detITk72rbPb7SQnJ7NixYoKt1mxYkW59gBDhgzxtd+5cydpaWnl2kRERNCvX7/j7rOoqAi3211uERERkYbL0gB08OBBPB4PcXFx5dbHxcWRlpZW4TZpaWknbH/k58nsc/LkyURERPiWpKSkKh2PiIiI+AfdZwdMmDCB7Oxs35KSkmJ1SSIiIlKLLA1A0dHROBwO0tPTy61PT08nPj6+wm3i4+NP2P7Iz5PZp8vlIjw8vNwiIiIiDZelAcjpdNKrVy8WLVrkW+f1elm0aBH9+/evcJv+/fuXaw+wcOFCX/s2bdoQHx9fro3b7WbVqlXH3aeIiIg0LpbfBj9+/HjGjh1L79696du3L9OmTSMvL49rr70WgGuuuYbmzZszefJkAO68807OOusspkyZwrBhw5g9ezZr167llVdeAcz5T+666y7+8Y9/0KFDB99t8ImJiYwYMcKqwxQREZF6xPIANHLkSA4cOMDEiRNJS0ujR48eLFiwwDeIec+ePdjtRzuqBgwYwHvvvcff//53HnzwQTp06MC8efN8cwAB3H///eTl5XHTTTeRlZXFoEGDWLBggeYAEhEREaAezANUH2keIBEREf/jN/MAiYiIiFhBAUhEREQaHQUgERERaXQUgERERKTRUQASERGRRkcBSERERBody+cBqo+OzAygp8KLiIj4jyPf25WZ4UcBqAI5OTkAeiq8iIiIH8rJySEiIuKEbTQRYgW8Xi/79+8nLCwMm81Wo/t2u90kJSWRkpKiSRZrmc513dG5rjs613VH57ru1NS5NgyDnJwcEhMTyz1FoiLqAaqA3W6nRYsWtfoZeup83dG5rjs613VH57ru6FzXnZo413/U83OEBkGLiIhIo6MAJCIiIo2OAlAdc7lcPPLII7hcLqtLafB0ruuOznXd0bmuOzrXdceKc61B0CIiItLoqAdIREREGh0FIBEREWl0FIBERESk0VEAEhERkUZHAagOzZgxg9atWxMUFES/fv1YvXq11SX5vcmTJ9OnTx/CwsKIjY1lxIgRbN26tVybwsJCbr31Vpo1a0ZoaCiXXXYZ6enpFlXccDz55JPYbDbuuusu3zqd65qzb98+rrrqKpo1a0ZwcDBdu3Zl7dq1vvcNw2DixIkkJCQQHBxMcnIy27dvt7Bi/+TxeHj44Ydp06YNwcHBtGvXjscff7zcs6R0rqtm6dKlDB8+nMTERGw2G/PmzSv3fmXO6+HDhxkzZgzh4eFERkZy/fXXk5ubWyP1KQDVkTlz5jB+/HgeeeQR1q9fT/fu3RkyZAgZGRlWl+bXlixZwq233srKlStZuHAhJSUlnH/++eTl5fna3H333Xz22Wd8+OGHLFmyhP379/PnP//Zwqr935o1a3j55Zfp1q1bufU61zUjMzOTgQMHEhgYyJdffslPP/3ElClTaNq0qa/N008/zfPPP8/MmTNZtWoVTZo0YciQIRQWFlpYuf956qmneOmll5g+fTpbtmzhqaee4umnn+aFF17wtdG5rpq8vDy6d+/OjBkzKny/Mud1zJgxbN68mYULF/L555+zdOlSbrrpppop0JA60bdvX+PWW2/1/e7xeIzExERj8uTJFlbV8GRkZBiAsWTJEsMwDCMrK8sIDAw0PvzwQ1+bLVu2GICxYsUKq8r0azk5OUaHDh2MhQsXGmeddZZx5513Goahc12T/va3vxmDBg067vter9eIj483nnnmGd+6rKwsw+VyGe+//35dlNhgDBs2zLjuuuvKrfvzn/9sjBkzxjAMneuaAhhz5871/V6Z8/rTTz8ZgLFmzRpfmy+//NKw2WzGvn37ql2TeoDqQHFxMevWrSM5Odm3zm63k5yczIoVKyysrOHJzs4GICoqCoB169ZRUlJS7tyfcsoptGzZUue+im699VaGDRtW7pyCznVN+vTTT+nduzdXXHEFsbGx9OzZk1dffdX3/s6dO0lLSyt3riMiIujXr5/O9UkaMGAAixYtYtu2bQB8//33LFu2jAsuuADQua4tlTmvK1asIDIykt69e/vaJCcnY7fbWbVqVbVr0MNQ68DBgwfxeDzExcWVWx8XF8fPP/9sUVUNj9fr5a677mLgwIGcdtppAKSlpeF0OomMjCzXNi4ujrS0NAuq9G+zZ89m/fr1rFmz5pj3dK5rzq+//spLL73E+PHjefDBB1mzZg133HEHTqeTsWPH+s5nRX+n6FyfnAceeAC3280pp5yCw+HA4/Hwz3/+kzFjxgDoXNeSypzXtLQ0YmNjy70fEBBAVFRUjZx7BSBpMG699VY2bdrEsmXLrC6lQUpJSeHOO+9k4cKFBAUFWV1Og+b1eunduzdPPPEEAD179mTTpk3MnDmTsWPHWlxdw/LBBx/w7rvv8t5779GlSxc2btzIXXfdRWJios51A6dLYHUgOjoah8NxzN0w6enpxMfHW1RVw3Lbbbfx+eef891339GiRQvf+vj4eIqLi8nKyirXXuf+5K1bt46MjAxOP/10AgICCAgIYMmSJTz//PMEBAQQFxenc11DEhIS6Ny5c7l1p556Knv27AHwnU/9nVJ99913Hw888ACjRo2ia9euXH311dx9991MnjwZ0LmuLZU5r/Hx8cfcKFRaWsrhw4dr5NwrANUBp9NJr169WLRokW+d1+tl0aJF9O/f38LK/J9hGNx2223MnTuXb7/9ljZt2pR7v1evXgQGBpY791u3bmXPnj069yfp3HPP5ccff2Tjxo2+pXfv3owZM8b3Wue6ZgwcOPCY6Ry2bdtGq1atAGjTpg3x8fHlzrXb7WbVqlU61ycpPz8fu738V6HD4cDr9QI617WlMue1f//+ZGVlsW7dOl+bb7/9Fq/XS79+/apfRLWHUUulzJ4923C5XMasWbOMn376ybjpppuMyMhIIy0tzerS/Nott9xiREREGIsXLzZSU1N9S35+vq/NzTffbLRs2dL49ttvjbVr1xr9+/c3+vfvb2HVDcdv7wIzDJ3rmrJ69WojICDA+Oc//2ls377dePfdd42QkBDjnXfe8bV58sknjcjISOOTTz4xfvjhB+OSSy4x2rRpYxQUFFhYuf8ZO3as0bx5c+Pzzz83du7caXz88cdGdHS0cf/99/va6FxXTU5OjrFhwwZjw4YNBmBMnTrV2LBhg7F7927DMCp3XocOHWr07NnTWLVqlbFs2TKjQ4cOxujRo2ukPgWgOvTCCy8YLVu2NJxOp9G3b19j5cqVVpfk94AKlzfffNPXpqCgwPjrX/9qNG3a1AgJCTEuvfRSIzU11bqiG5DfByCd65rz2WefGaeddprhcrmMU045xXjllVfKve/1eo2HH37YiIuLM1wul3HuuecaW7dutaha/+V2u40777zTaNmypREUFGS0bdvWeOihh4yioiJfG53rqvnuu+8q/Pt57NixhmFU7rweOnTIGD16tBEaGmqEh4cb1157rZGTk1Mj9dkM4zfTXYqIiIg0AhoDJCIiIo2OApCIiIg0OgpAIiIi0ugoAImIiEijowAkIiIijY4CkIiIiDQ6CkAiIiLS6CgAiYhUwuLFi7HZbMc860xE/JMCkIiIiDQ6CkAiIiLS6CgAiYhf8Hq9TJ48mTZt2hAcHEz37t35z3/+Axy9PDV//ny6detGUFAQZ5xxBps2bSq3j48++oguXbrgcrlo3bo1U6ZMKfd+UVERf/vb30hKSsLlctG+fXtef/31cm3WrVtH7969CQkJYcCAAcc8tV1E/IMCkIj4hcmTJ/P2228zc+ZMNm/ezN13381VV13FkiVLfG3uu+8+pkyZwpo1a4iJiWH48OGUlJQAZnC58sorGTVqFD/++COPPvooDz/8MLNmzfJtf8011/D+++/z/PPPs2XLFl5++WVCQ0PL1fHQQw8xZcoU1q5dS0BAANddd12dHL+I1Cw9DFVE6r2ioiKioqL45ptv6N+/v2/9DTfcQH5+PjfddBNnn302s2fPZuTIkQAcPnyYFi1aMGvWLK688krGjBnDgQMH+Prrr33b33///cyfP5/Nmzezbds2OnXqxMKFC0lOTj6mhsWLF3P22WfzzTffcO655wLwxRdfMGzYMAoKCggKCqrlsyAiNUk9QCJS7+3YsYP8/HzOO+88QkNDfcvbb7/NL7/84mv323AUFRVFp06d2LJlCwBbtmxh4MCB5fY7cOBAtm/fjsfjYePGjTgcDs4666wT1tKtWzff64SEBAAyMjKqfYwiUrcCrC5AROSP5ObmAjB//nyaN29e7j2Xy1UuBFVVcHBwpdoFBgb6XttsNsAcnyQi/kU9QCJS73Xu3BmXy8WePXto3759uSUpKcnXbuXKlb7XmZmZbNu2jVNPPRWAU089leXLl5fb7/Lly+nYsSMOh4OuXbvi9XrLjSkSkYZLPUAiUu+FhYVx7733cvfdd+P1ehk0aBDZ2dksX76c8PBwWrVqBcBjjz1Gs2bNiIuL46GHHiI6OpoRI0YAcM8999CnTx8ef/xxRo4cyYoVK5g+fTovvvgiAK1bt2bs2LFcd911PP/883Tv3p3du3eTkZHBlVdeadWhi0gtUQASEb/w+OOPExMTw+TJk/n111+JjIzk9NNP58EHH/RdgnryySe588472b59Oz169OCzzz7D6XQCcPrpp/PBBx8wceJEHn/8cRISEnjssccYN26c7zNeeuklHnzwQf76179y6NAhWrZsyYMPPmjF4YpILdNdYCLi947coZWZmUlkZKTV5YiIH9AYIBEREWl0FIBERESk0dElMBEREWl01AMkIiIijY4CkIiIiDQ6CkAiIiLS6CgAiYiISKOjACQiIiKNjgKQiIiINDoKQCIiItLoKACJiIhIo6MAJCIiIo3O/wMDjIGc/Ov6ZQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot history for accuracy\n",
        "plt.plot(history.history['categorical_accuracy'])\n",
        "plt.plot(history.history['val_categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "# Plot history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqWsXxfZGI46"
      },
      "source": [
        "### Tune Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDxgbHOHGI46",
        "outputId": "c91ee280-d643-4660-85d0-5186ced9beee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTaISdyDGI46"
      },
      "outputs": [],
      "source": [
        "import keras_tuner\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OFVObA3GI46"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    layer_index = 0\n",
        "    for i in range(hp.Int(name='num_layers',min_value=1,max_value=3)):\n",
        "        if layer_index == 0:\n",
        "            model.add(Dense(hp.Int(name='hidden_units_'+str(i),min_value=128,max_value=512,step=64),\n",
        "                            activation=hp.Choice(name='activation_layer'+str(i),values=['relu','tanh']),\n",
        "                            input_dim=X_train_svd.shape[1]\n",
        "                           ))\n",
        "            model.add(Dropout(hp.Choice(name='dropout_layer_'+str(i),values=[0.1,0.2,0.3,0.4,0.5])))\n",
        "        else:\n",
        "            model.add(Dense(hp.Int(name='hidden_units_'+str(i),min_value=128,max_value=512,step=64),\n",
        "                            activation=hp.Choice(name='activation_layer'+str(i),values=['relu','tanh'])))\n",
        "            model.add(Dropout(hp.Choice(name='dropout_layer_'+str(i),values=[0.1,0.2,0.3,0.4,0.5])))\n",
        "\n",
        "        layer_index += 1\n",
        "\n",
        "    # Add last layer that produces the logits\n",
        "    model.add(Dense(len(df.LABEL.unique()),  activation='softmax'))\n",
        "\n",
        "    # Tune the learning rate for the optimizer by choosing an optimal value from 0.01, 0.001, or 0.0001\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2,1e-3,1e-4])\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "                  metrics=[CategoricalAccuracy()])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7fGoNc6GI46",
        "outputId": "0ebcbd11-9963-4d25-97bc-27908434d827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
            "hidden_units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
            "activation_layer0 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "dropout_layer_0 (Choice)\n",
            "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.2, 0.3, 0.4, 0.5], 'ordered': True}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ],
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the Keras Tuner RandomSearch object\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective=kt.Objective(\"val_categorical_accuracy\", direction=\"max\"),\n",
        "                        max_trials = 20,\n",
        "                        directory='KT_dir',\n",
        "                        project_name='KT_tuning')\n",
        "\n",
        "# Define EarlyStopping callback to stop training if validation loss stops decreasing\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', patience=10)   # Number of epochs with no improvement before stopping\n",
        "\n",
        "# Print a summary of the search space for tuning\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZznnC59KGI47",
        "outputId": "607f2ed4-1ce8-4d54-ca5d-99f9f9a56d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 12s]\n",
            "val_categorical_accuracy: 0.6865161061286926\n",
            "\n",
            "Best val_categorical_accuracy So Far: 0.6872005462646484\n",
            "Total elapsed time: 00h 04m 05s\n"
          ]
        }
      ],
      "source": [
        "tuner.search(X_train_svd, y_train_1_hot,\n",
        "             validation_data=(X_val_svd, y_val_1_hot), epochs=50, batch_size = 128,\n",
        "             callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6DD6583GI47",
        "outputId": "67ca090e-7e50-4343-988b-97334272b3f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in KT_dir/KT_tuning\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_categorical_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "hidden_units_0: 512\n",
            "activation_layer0: relu\n",
            "dropout_layer_0: 0.2\n",
            "learning_rate: 0.001\n",
            "hidden_units_1: 128\n",
            "activation_layer1: relu\n",
            "dropout_layer_1: 0.1\n",
            "hidden_units_2: 128\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.1\n",
            "Score: 0.6872005462646484\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "hidden_units_0: 256\n",
            "activation_layer0: relu\n",
            "dropout_layer_0: 0.2\n",
            "learning_rate: 0.001\n",
            "hidden_units_1: 256\n",
            "activation_layer1: tanh\n",
            "dropout_layer_1: 0.4\n",
            "hidden_units_2: 384\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.3\n",
            "Score: 0.6872005462646484\n",
            "\n",
            "Trial 19 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "hidden_units_0: 512\n",
            "activation_layer0: relu\n",
            "dropout_layer_0: 0.5\n",
            "learning_rate: 0.01\n",
            "hidden_units_1: 512\n",
            "activation_layer1: tanh\n",
            "dropout_layer_1: 0.2\n",
            "hidden_units_2: 448\n",
            "activation_layer2: tanh\n",
            "dropout_layer_2: 0.4\n",
            "Score: 0.6865161061286926\n",
            "\n",
            "Trial 12 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "hidden_units_0: 256\n",
            "activation_layer0: relu\n",
            "dropout_layer_0: 0.1\n",
            "learning_rate: 0.01\n",
            "hidden_units_1: 128\n",
            "activation_layer1: relu\n",
            "dropout_layer_1: 0.2\n",
            "hidden_units_2: 256\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.3\n",
            "Score: 0.6844627261161804\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "hidden_units_0: 256\n",
            "activation_layer0: relu\n",
            "dropout_layer_0: 0.1\n",
            "learning_rate: 0.01\n",
            "hidden_units_1: 256\n",
            "activation_layer1: relu\n",
            "dropout_layer_1: 0.1\n",
            "hidden_units_2: 384\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.4\n",
            "Score: 0.6837782263755798\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "hidden_units_0: 512\n",
            "activation_layer0: tanh\n",
            "dropout_layer_0: 0.5\n",
            "learning_rate: 0.001\n",
            "hidden_units_1: 256\n",
            "activation_layer1: tanh\n",
            "dropout_layer_1: 0.5\n",
            "hidden_units_2: 320\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.2\n",
            "Score: 0.6837782263755798\n",
            "\n",
            "Trial 11 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "hidden_units_0: 384\n",
            "activation_layer0: relu\n",
            "dropout_layer_0: 0.2\n",
            "learning_rate: 0.01\n",
            "hidden_units_1: 192\n",
            "activation_layer1: relu\n",
            "dropout_layer_1: 0.5\n",
            "hidden_units_2: 192\n",
            "activation_layer2: tanh\n",
            "dropout_layer_2: 0.5\n",
            "Score: 0.683093786239624\n",
            "\n",
            "Trial 15 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "hidden_units_0: 512\n",
            "activation_layer0: tanh\n",
            "dropout_layer_0: 0.1\n",
            "learning_rate: 0.0001\n",
            "hidden_units_1: 256\n",
            "activation_layer1: relu\n",
            "dropout_layer_1: 0.3\n",
            "hidden_units_2: 320\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.4\n",
            "Score: 0.6824092864990234\n",
            "\n",
            "Trial 10 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "hidden_units_0: 448\n",
            "activation_layer0: tanh\n",
            "dropout_layer_0: 0.4\n",
            "learning_rate: 0.001\n",
            "hidden_units_1: 512\n",
            "activation_layer1: tanh\n",
            "dropout_layer_1: 0.5\n",
            "hidden_units_2: 448\n",
            "activation_layer2: relu\n",
            "dropout_layer_2: 0.3\n",
            "Score: 0.6817248463630676\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "hidden_units_0: 384\n",
            "activation_layer0: tanh\n",
            "dropout_layer_0: 0.5\n",
            "learning_rate: 0.01\n",
            "hidden_units_1: 448\n",
            "activation_layer1: relu\n",
            "dropout_layer_1: 0.5\n",
            "hidden_units_2: 256\n",
            "activation_layer2: tanh\n",
            "dropout_layer_2: 0.5\n",
            "Score: 0.6810404062271118\n"
          ]
        }
      ],
      "source": [
        "# Trials summary\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRx2IUBgGI47",
        "outputId": "f424c29b-6bf3-4fd8-9262-c359434760b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_layers': 3,\n",
              " 'hidden_units_0': 512,\n",
              " 'activation_layer0': 'relu',\n",
              " 'dropout_layer_0': 0.2,\n",
              " 'learning_rate': 0.001,\n",
              " 'hidden_units_1': 128,\n",
              " 'activation_layer1': 'relu',\n",
              " 'dropout_layer_1': 0.1,\n",
              " 'hidden_units_2': 128,\n",
              " 'activation_layer2': 'relu',\n",
              " 'dropout_layer_2': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Get best hyper-parameters setup\n",
        "tuner.get_best_hyperparameters()[0].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bNQjk62GI47",
        "outputId": "1b7922f6-48dd-40db-f2c9-71e9c287db20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               512512    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 595075 (2.27 MB)\n",
            "Trainable params: 595075 (2.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKU-V2bvGI47",
        "outputId": "2468b844-cf85-4f63-9076-dea2e15a7f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 5ms/step\n",
            "[1 1 0 ... 0 1 1]\n"
          ]
        }
      ],
      "source": [
        "predictions = np.argmax(best_model.predict(X_val_svd), -1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPMyOm9iGI48",
        "outputId": "f9a41d35-6a15-4e8f-da25-e4af453f04b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'neutral', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'positive', 'neutral', 'positive', 'negative', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'neutral', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'neutral', 'negative', 'positive', 'negative', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'positive', 'negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'neutral', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'negative', 'positive', 'neutral', 'negative', 'positive', 'positive', 'negative', 'neutral', 'positive', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'negative', 'neutral', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'negative', 'negative', 'neutral', 'positive', 'positive', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'positive', 'positive', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'negative', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'positive', 'neutral', 'negative', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral']\n"
          ]
        }
      ],
      "source": [
        "# Create a dictionary to map class labels to class names\n",
        "label_to_name = {i: name for i, name in enumerate(pd.get_dummies(y_val).columns)}\n",
        "\n",
        "# Replace integer class labels in predictions with class names\n",
        "predictions_with_names = [label_to_name[label] for label in predictions]\n",
        "\n",
        "print(predictions_with_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCfjUz8-GI48"
      },
      "source": [
        "### Best MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P8xwZn_GI48",
        "outputId": "560baf81-f357-4d84-830a-12093d928f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.66      0.67      0.67       426\n",
            "     neutral       0.64      0.67      0.66       552\n",
            "    positive       0.76      0.72      0.74       483\n",
            "\n",
            "    accuracy                           0.69      1461\n",
            "   macro avg       0.69      0.69      0.69      1461\n",
            "weighted avg       0.69      0.69      0.69      1461\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the best model performance after hyperparameters tuning\n",
        "\n",
        "print(classification_report(y_val, predictions_with_names))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DFZZBmZlGI4z",
        "nFsdWZAQGI42",
        "BlE0XcgsGI42",
        "GGcngnSfGI43",
        "lu4mRBshGI44",
        "QFLwpI3CGI45",
        "R4LWX78WGI45",
        "-uQ22l_2GI45",
        "xqWsXxfZGI46",
        "iCfjUz8-GI48"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}